<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>Data Collection | 지혁&#39;s Blog</title>
  
  

  
  <link rel="alternate" href="/feed.xml" title="지혁's Blog">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- Auto Canonical -->
  <link rel="canonical" href="http://jungjihyuk.github.io/2019/07/15/data-collection/"/>

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  
    
<link rel="stylesheet" href="/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  

  <!-- Google AdSense -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143236286-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-143236286-2');
</script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/feed.xml" title="지혁's Blog" type="application/rss+xml">
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>Imitation, Imagination, Integration</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="search" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;Home
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/about"
            
              rel="nofollow"
            
            
            id="about">
            <i class='fas fa-info-circle fa-fw'></i>&nbsp;About
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" target="_self" href='/' >
        
          지혁's Blog
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/"
                  
                  
                    target="_self"
                  
                  id="home">
									<i class='fas fa-grin fa-fw'></i>&nbsp;Home
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives"
                  
                    rel="nofollow"
                  
                  
                    target="_self"
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;Archives
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;Home
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;Archives
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/projects"
                
                
                id="projects">
								<i class='fas fa-code-branch fa-fw'></i>&nbsp;Projects
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="https://xaoxuu.com/wiki/material-x/"
                
                  rel="nofollow"
                
                
                id="https:xaoxuu.comwikimaterial-x">
								<i class='fas fa-book fa-fw'></i>&nbsp;Reference
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/about"
                
                  rel="nofollow"
                
                
                id="about">
								<i class='fas fa-info-circle fa-fw'></i>&nbsp;About
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  
    <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2019/07/15/data-collection/">
        Data Collection
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="http://jungjihyuk.github.io" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>Jihyuk Jung</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-07-15</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/AI/Data-Analysis/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>AI&nbsp;/&nbsp;Data Analysis</p>
    </a>
  </div>


          
        
          
            
  


          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <h1 id="Data-Collection"><a href="#Data-Collection" class="headerlink" title="Data Collection"></a>Data Collection</h1><blockquote>
<p>데이터 수집은 왜 하는 걸까??</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">4차 산업혁명 시대를 사는 현대인들 중 Big Data에 관한 존재를 모르는 사람은 없을 것이다</span><br><span class="line">Big Data는 방대한 데이터고 그 많은 데이터로 뭐 어떻게 해보려는 시도가 있다는 건 알겠는데</span><br><span class="line">도대체 그 Big Data라는 것으로 뭘 하는 걸까?</span><br><span class="line"></span><br><span class="line">마냥 많은 데이터라는 것에서 그쳤으면 Big Data가 이슈가 되지 않았을 것이다</span><br><span class="line">Big Data라는 엄청난 데이터 속에서 사람의 인지 능력으로는 분석하기 힘든 양을</span><br><span class="line">한꺼번에 컴퓨터라는 도구로 분석을 해보니 사람보다 연산도 빠르고 분석 성능이 좋았던 것이다</span><br><span class="line"></span><br><span class="line">따라서 Big Data(Data warehouse)를 수집해서 숨겨진 의미 있는 정보를 추출하고</span><br><span class="line">문제를 해결하는 것이 화두가 된 것이다</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Data-수집-종류"><a href="#Data-수집-종류" class="headerlink" title="Data 수집 종류"></a>Data 수집 종류</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 공공데이터(api, file)</span><br><span class="line">2. Portal site ( ex) google, naver, daum..)</span><br><span class="line">3. 그 외 Files, Databases</span><br></pre></td></tr></table></figure>

<blockquote>
<p>공공 데이터 api나 file 그리고 dataset(file)은 데이터를 수집하는 절차가 복잡하거나 수집해서 <br><br>처리하는 작업이 번거롭거나 힘들지 않다 <br><br>그런데 Portal site에서 데이터를 수집하기 위해서는 제법 까다로운 작업이 필요하다</p>
</blockquote>
<br>


<h2 id="Web-Crawling은-불법"><a href="#Web-Crawling은-불법" class="headerlink" title="Web Crawling은 불법?"></a>Web Crawling은 불법?</h2><blockquote>
<p>결론적으로 말해서 모든 Crawling, Scraping은 불법이 아니다. <br><br>하지만 대부분 불법이므로 주의 해야 한다</p>
</blockquote>
<br>

<h3 id="어떤-것이-합법인가"><a href="#어떤-것이-합법인가" class="headerlink" title="어떤 것이 합법인가?"></a>어떤 것이 합법인가?</h3><h4 id="Opt-in-vs-Opt-out"><a href="#Opt-in-vs-Opt-out" class="headerlink" title="Opt-in vs Opt-out"></a>Opt-in vs Opt-out</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Opt-in : 정보 수집에 대해 동의를 얻고나서 수집하는 경우  (whitelist)</span><br><span class="line"></span><br><span class="line">Opt-out : 처음에 정보 제공자에 대해 동의를 얻지 않고 당사자의 거부 의사를 밝혔을 때  </span><br><span class="line">          정보 수집 중단을 하는 경우 (blacklist)</span><br></pre></td></tr></table></figure>

<p><span style="color: skyblue; font-size: 20px">Crawling하는 입장에서는 Opt-out 방법으로 정보를 수집한다</span><br><br><span style="color: skyblue; font-size: 20px">따라서 해당 사이트에서 robots.txt에 명시적으로 거부하지 않은 경우, 메인페이지 하단에 crawling 금지 표시가 없는 경우만 정보 수집이 가능하다. </span><br></p>
<p><img src="https://user-images.githubusercontent.com/33630505/61589769-fe148c80-abe9-11e9-815c-b069edd7f602.png" alt="robots"></p>
<br>

<h2 id="Data-from-Portal-site-Web-Data"><a href="#Data-from-Portal-site-Web-Data" class="headerlink" title="Data from Portal site(Web Data)"></a>Data from Portal site(Web Data)</h2><blockquote>
<p>Web으로부터 데이터를 수집하겠다고 마음 먹은 순간 해야할 작업들이 많다</p>
</blockquote>
<br>
<hr>

<h2 id="Crawling부터-DB-저장까지-Flow"><a href="#Crawling부터-DB-저장까지-Flow" class="headerlink" title="Crawling부터 DB 저장까지 Flow"></a>Crawling부터 DB 저장까지 Flow</h2><p><img src="https://user-images.githubusercontent.com/33630505/61589402-56489000-abe4-11e9-9e49-dbe35c4a7fad.jpg" alt="crawlingandscraping"><br>사진 출처: 논문[RCrawler: An R package for parallel web crawling and scraping -Salim Khalil, Mohamed Fakir]  <br><br><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Data 수집원 OK? ⇒ Dynamic HTML  ⇒  Focused?   ⇒ Selenium + Crawling + url check ⇒ Scraping  &#x3D;&gt; DB</span><br><span class="line">                                      BFS?     ⇒ Selenium + Crawling ⇒ Scraping ⇒ DB</span><br><span class="line">                      HTML      ⇒  Focused?   ⇒ Crawling + url check ⇒ Scraping ⇒ DB</span><br><span class="line">                                      BFS?     ⇒ Crawling ⇒ Scraping ⇒ DB</span><br></pre></td></tr></table></figure>
<br>

<p><span style="color: skyblue; font-size: 20px">데이터를 가져오려면 Web page 구성을 알아야 한다!</span><br></p>
<blockquote>
<p>HTML, CSS, JavaScript등 웹 페이지 구성이 어떻게 되는지 공부해야 한다 <br><br>사이트 마다 웹 페이지 구성이 다르기 때문에 웹에 대한 이해 없이 무작정 하면 <br><br>데이터 수집이 안되는 경우를 발견하게 될 것이다 <br></p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/33630505/61360601-ba541700-a8b9-11e9-9031-d4271168bf10.JPG" alt="lifecycle"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">어떠한 웹 페이지는 요청한 부분만 동적으로 페이지 리로딩 없이 데이터를 가져 와서</span><br><span class="line">request url을 확인하기 어려운 경우가 있다.</span><br><span class="line"></span><br><span class="line">위 그림에 SPA Lifecycle이 그러한 경우 인데,</span><br><span class="line">사용자가 직접 클릭을 해야만 데이터를 확인 할 수 페이지라면</span><br><span class="line">처음에 요청했던 페이지에는 포함되어 있지 않고 클릭 한 순간</span><br><span class="line">dom객체가 추가 되기 때문에 실시간으로 개발자 도구에서 network 부분을 살피지 않는다면</span><br><span class="line">절대 숨겨진 데이터를 가져올 수 없을 것이다.</span><br><span class="line"></span><br><span class="line">따라서 어떠한 웹 페이지 인지에 따라 셀레늄같은 automation framework를 사용할지 말지 결정해야 한다.</span><br></pre></td></tr></table></figure>

<p><span style="color: orange">잘 모른다면 참고하자 =&gt;</span> <a href="https://jungjihyuk.github.io/JH_Life/objectModel/">Object Model</a><br></p>
<br>

<p><span style="color: skyblue; font-size: 20px">웹 문서 중 어디서부터 어디까지 찾을 껀데? 수집 범위는 정했니?</span><br></p>
<blockquote>
<p>지금부터는 Crawling 기법으로 Hyperlink fetch를 반복해서 페이지 사이 link 구조를 알아내야 한다 <br><br>그 다음 depth를 설정해서 어디까지 crawling 할 것인가를 정하고 focused crawling으로 crawling하는 페이지를 <br><br>한정 할 것인지 아니면 페이지를 넘나들며 끊임없이 확장할 것인지도 정해야 한다 (목적에 맞게) <br><br>이러한 경우를 DFS(Depth First Search)와 BFS(Breadth First Search)라고 한다 <br></p>
</blockquote>
<br>

<p><span style="color: skyblue; font-size: 20px">Crawling해서 많은 url은 확보 했는데 어떤 url에 유용한 정보가 있는지 아니?</span><br></p>
<blockquote>
<p>url만으로 정보의 유용성을 판단할 수는 없다 <br><br>따라서 crawling 해서 database에 저장할때 page rank 개념을 활용하여 저장하는 것이 효율적이다 <br><br>page rank개념은 페이지 참조횟수가 많으면 그만큼 영향력 있고, 가치가 있는 데이터를 포함한 페이지라 간주한다 <br><br>결국 page rank가 높은 순으로 url을 분류하고 그 url로 부터 data를 수집 하면 된다</p>
</blockquote>
<p><span style="color: rgb(180, 75, 92); font-size: 15px;">단, page rank가 높다고 나한테 필요한 데이터라는 보장은 없다.</span><br><br><span style="color: rgb(180, 75, 92); font-size: 15px;">그래서 데이터 추출후 전처리, 패턴 분석 등 여러가지 처리 후 데이터를 사용해야 한다.</span><br></p>
<p><a href="#crawling">Crawling 공부하러가기</a></p>
<br>

<p><span style="color: skyblue; font-size: 20px">유용한 page url을 알아 냈으니 내가 원하는 data를 수집하자</span><br></p>
<blockquote>
<p>scraping</p>
</blockquote>
<p><a href="#scraping">Scraping 공부하러가기</a></p>
<br>
<hr>


<h2 id="Data-mining"><a href="#Data-mining" class="headerlink" title="Data mining"></a>Data mining</h2><p>Data mining 출처: <a href="http://www.incodom.kr/Data_mining_%EC%A0%95%EC%9D%98#h_9e737f73b091295d98128515d2729bbb" target="_blank" rel="noopener">incodom</a><br></p>
<br>

<h2 id="Crawling-vs-Scraping"><a href="#Crawling-vs-Scraping" class="headerlink" title="Crawling vs Scraping"></a>Crawling vs Scraping</h2><p><img src="https://user-images.githubusercontent.com/33630505/61361477-8548c400-a8bb-11e9-9b09-7b1804aaf054.JPG" alt="crawlerandscraping"></p>
<p>사진출처: <a href="http://prowebscraping.com/web-scraping-vs-web-crawling/" target="_blank" rel="noopener">prowebscraping</a><br></p>
<br>

<p><a id = 'crawling'></a></p>
<h2 id="Crawling"><a href="#Crawling" class="headerlink" title="Crawling"></a>Crawling</h2><h3 id="BFS-Crawling"><a href="#BFS-Crawling" class="headerlink" title="BFS Crawling"></a>BFS Crawling</h3><blockquote>
<p>google 박보영 검색 결과 crawling</p>
</blockquote>
<br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;<span class="string">"user-agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36"</span>&#125;  <span class="comment"># 브라우저에서 직접 request보내는 것처럼 흉내내기 위한 header 초기화</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time, requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(method, url, param=None, data=None, timeout=<span class="number">1</span>, maxretries=<span class="number">3</span>, headers = headers)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        resp = requests.request(method, url, params = param, data =  data, headers = headers)  <span class="comment"># request요청에 대한 response</span></span><br><span class="line">        resp.raise_for_status() <span class="comment"># 에러 강제하기</span></span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> e:    <span class="comment"># 에러 처리</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">500</span> &lt;= e.response.status_code &lt; <span class="number">600</span> <span class="keyword">and</span> maxretries &gt;<span class="number">0</span>):</span><br><span class="line">            print(maxretries)</span><br><span class="line">            time.sleep(timeout)</span><br><span class="line">            resp=download3(method, url, param, data, timeout, maxretries<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">else</span>:          </span><br><span class="line">            print(e.response.status_code)</span><br><span class="line">            print(e.response.reason)</span><br><span class="line">    <span class="keyword">return</span> resp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseURL</span><span class="params">(seed)</span>:</span>      <span class="comment"># download함수와 BeautifulSoup을 이용해 URL parsing 하는 함수</span></span><br><span class="line">    html = download(<span class="string">"get"</span>, seed)</span><br><span class="line">    dom = BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [requests.compat.urljoin(seed, _[<span class="string">"href"</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> dom.find_all(<span class="string">"a"</span>)  <span class="keyword">if</span> _.has_attr(<span class="string">"href"</span>) <span class="keyword">and</span> len(_[<span class="string">"href"</span>]) &gt; <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.google.com/search"</span></span><br><span class="line">html = download(<span class="string">"get"</span>, url, param = &#123;<span class="string">"q"</span>:<span class="string">"박보영"</span>&#125;)</span><br><span class="line">dom = BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">queue = list()</span><br><span class="line">queue.extend([_.find_parent()[<span class="string">'href'</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> dom.select(<span class="string">".LC20lb"</span>)]) <span class="comment"># 초기 seed값 추가</span></span><br><span class="line">seen = list()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> queue:</span><br><span class="line">    baseURL = queue.pop(<span class="number">0</span>)   <span class="comment"># queue는 선입 선출 방식이기 때문에 index 가장 앞 0을 꺼낸다</span></span><br><span class="line">    seen.append(baseURL)   <span class="comment"># 한번 꺼낸 url은 재방문 하지 않도록 seen list에 추가</span></span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">5</span>)    <span class="comment"># 빈번한 request로 block 당하는 일 방지하기 위해 시간 끌기</span></span><br><span class="line"></span><br><span class="line">    linkList = parseURL(baseURL)  <span class="comment"># parsing한 url list에 추가</span></span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> linkList:  <span class="comment"># 추가된 url을 하나씩 뽑아 queue에 없거나 seen에 없으면 queue에 추가한다</span></span><br><span class="line">        <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> queue <span class="keyword">and</span> link <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">            queue.append(link)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Queue: &#123;0&#125;, Seen: &#123;1&#125;"</span>.format(len(queue), len(seen)))</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">Queue: <span class="number">862</span>, Seen: <span class="number">1</span></span><br><span class="line">Queue: <span class="number">1291</span>, Seen: <span class="number">2</span></span><br><span class="line">Queue: <span class="number">2259</span>, Seen: <span class="number">3</span></span><br><span class="line">Queue: <span class="number">2381</span>, Seen: <span class="number">4</span></span><br><span class="line">Queue: <span class="number">2416</span>, Seen: <span class="number">5</span></span><br><span class="line">Queue: <span class="number">2426</span>, Seen: <span class="number">6</span></span><br><span class="line">.....</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>


<h3 id="DFS-Crawling-Focused-Crawling"><a href="#DFS-Crawling-Focused-Crawling" class="headerlink" title="DFS Crawling(Focused Crawling)"></a>DFS Crawling(Focused Crawling)</h3><blockquote>
<p>naver에 박보영 검색 후 블로그 url parsing</p>
</blockquote>
<br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests, download</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkBlog</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> requests.compat.urlparse(url)[<span class="number">1</span>] == <span class="string">"blog.naver.com"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseURL</span><span class="params">(seed)</span>:</span></span><br><span class="line">    html = download.download(<span class="string">"get"</span>, seed)</span><br><span class="line">    dom = download.BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(dom.select(<span class="string">"#mainFrame"</span>)) &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">    seed = requests.compat.urljoin(seed, dom.select(<span class="string">"#mainFrame"</span>)[<span class="number">0</span>][<span class="string">"src"</span>])</span><br><span class="line"></span><br><span class="line">    html = download.download(<span class="string">"get"</span>, seed)</span><br><span class="line">    dom = download.BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#     print(requests.compat.urljoin(seed, dom.select("#mainFrame")[0]['src']))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [requests.compat.urljoin(seed, _[<span class="string">"href"</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> dom.find_all(<span class="string">"a"</span>)  <span class="keyword">if</span> _.has_attr(<span class="string">"href"</span>)</span><br><span class="line">            <span class="keyword">and</span> len(_[<span class="string">"href"</span>]) &gt; <span class="number">3</span> <span class="keyword">and</span> checkBlog(requests.compat.urljoin(seed, _[<span class="string">'href'</span>]))]</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://search.naver.com/search.naver"</span></span><br><span class="line">html = download.download(<span class="string">"get"</span>, url, param = &#123;<span class="string">"query"</span>:<span class="string">"박보영"</span>&#125;)</span><br><span class="line">dom = download.BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">queue = list()</span><br><span class="line">queue.extend([_[<span class="string">'href'</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> dom.select(<span class="string">"a.sh_blog_title._sp_each_url._sp_each_title"</span>) <span class="keyword">if</span> checkBlog(_[<span class="string">'href'</span>])])</span><br><span class="line">seen = list()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> queue:</span><br><span class="line">    baseURL = queue.pop(<span class="number">0</span>)</span><br><span class="line">    seen.append(baseURL)</span><br><span class="line"></span><br><span class="line">    download.time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    linkList = parseURL(baseURL)</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> linkList:</span><br><span class="line">        <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> queue <span class="keyword">and</span> link <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">            queue.append(link)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Queue: &#123;0&#125;, Seen: &#123;1&#125;"</span>.format(len(queue), len(seen)))</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">Queue: <span class="number">17</span>, Seen: <span class="number">1</span></span><br><span class="line">Queue: <span class="number">32</span>, Seen: <span class="number">2</span></span><br><span class="line">Queue: <span class="number">48</span>, Seen: <span class="number">3</span></span><br><span class="line">Queue: <span class="number">47</span>, Seen: <span class="number">4</span></span><br><span class="line">Queue: <span class="number">46</span>, Seen: <span class="number">5</span></span><br><span class="line">Queue: <span class="number">45</span>, Seen: <span class="number">6</span></span><br><span class="line">Queue: <span class="number">44</span>, Seen: <span class="number">7</span></span><br><span class="line">Queue: <span class="number">43</span>, Seen: <span class="number">8</span></span><br><span class="line">....</span><br><span class="line">....</span><br></pre></td></tr></table></figure>

<p>crawling 출처: <a href="http://prowebscraping.com/web-scraping-vs-web-crawling/" target="_blank" rel="noopener">prowebscraping</a> &nbsp; <a href="https://www.quora.com/What-the-difference-between-crawling-website-and-counting-link-in-website" target="_blank" rel="noopener">quora</a> &nbsp; <a href="https://twoearth.tistory.com/19" target="_blank" rel="noopener">tistory</a> <br><br>논문: [RCrawler: An R package for parallel web crawling and scraping -Salim Khalil, Mohamed Fakir]  <br></p>
<br>

<h3 id="Crawling-한-url-DB에-저장하기"><a href="#Crawling-한-url-DB에-저장하기" class="headerlink" title="Crawling 한 url DB에 저장하기"></a>Crawling 한 url DB에 저장하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3, requests, download</span><br><span class="line"></span><br><span class="line">con = sqlite3.connect(<span class="string">"bot.db"</span>)</span><br><span class="line">cur = con.cursor()</span><br><span class="line"></span><br><span class="line">cur.executescript(<span class="string">'''</span></span><br><span class="line"><span class="string">    DROP TABLE IF EXISTS table1;</span></span><br><span class="line"><span class="string">    CREATE TABLE table1(</span></span><br><span class="line"><span class="string">        id INTEGER PRIMARY KEY AUTOINCREMENT,</span></span><br><span class="line"><span class="string">        table2_id INTEGER NOT NULL,</span></span><br><span class="line"><span class="string">        path TEXT NOT NULL,</span></span><br><span class="line"><span class="string">        param TEXT,</span></span><br><span class="line"><span class="string">        depth INTEGER NOT NULL,</span></span><br><span class="line"><span class="string">        inbound INTEGER NOT NULL,</span></span><br><span class="line"><span class="string">        seen BOOLEAN DEFAULT FALSE NOT NULL,</span></span><br><span class="line"><span class="string">        date TIMESTAMP DEFAUlT CURRENT_TIMESTAMP NOT NULL</span></span><br><span class="line"><span class="string">    );</span></span><br><span class="line"><span class="string">    DROP TABLE IF EXISTS table2;</span></span><br><span class="line"><span class="string">    CREATE TABLE table2(</span></span><br><span class="line"><span class="string">        id INTEGER PRIMARY KEY AUTOINCREMENT,</span></span><br><span class="line"><span class="string">        netloc TEXT NOT NULL,</span></span><br><span class="line"><span class="string">        date TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL</span></span><br><span class="line"><span class="string">    );</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.google.com/search"</span></span><br><span class="line">html = download.download(<span class="string">"get"</span>, url, param = &#123;<span class="string">"q"</span>: <span class="string">"박보영"</span>&#125;)</span><br><span class="line">dom = download.BeautifulSoup(html.text, <span class="string">"lxml"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseURL</span><span class="params">(seed)</span>:</span></span><br><span class="line">    html = download.download(<span class="string">"get"</span>, seed)</span><br><span class="line">    dom = download.BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [requests.compat.urljoin(seed, _[<span class="string">"href"</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> dom.find_all(<span class="string">"a"</span>)  <span class="keyword">if</span> _.has_attr(<span class="string">"href"</span>)</span><br><span class="line">            <span class="keyword">and</span> len(_[<span class="string">"href"</span>]) &gt; <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> [_.find_parent()[<span class="string">"href"</span>]</span><br><span class="line">             <span class="keyword">for</span> _ <span class="keyword">in</span> dom.select(<span class="string">".LC20lb"</span>)]:</span><br><span class="line">    _urlparse = requests.compat.urlparse(href)</span><br><span class="line">    netloc = <span class="string">"://"</span>.join(_urlparse[:<span class="number">2</span>])</span><br><span class="line">    cur.execute(<span class="string">"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1"</span>, [netloc]) <span class="comment">#netloc을 시퀀스로 만들어서 넘겨줘야함</span></span><br><span class="line"></span><br><span class="line">    netlocID = cur.fetchone()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> netlocID:</span><br><span class="line">        cur.execute(<span class="string">"INSERT INTO table2(netloc) VALUES(?)"</span>, [netloc])</span><br><span class="line"></span><br><span class="line">        con.commit()</span><br><span class="line"></span><br><span class="line">        cur.execute(<span class="string">"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1"</span>, [netloc])</span><br><span class="line"></span><br><span class="line">        netlocID = cur.fetchone()</span><br><span class="line"></span><br><span class="line">    cur.execute(<span class="string">"INSERT INTO table1(table2_id, path, param, depth, inbound) VALUES(?, ?, ?, ?, ?)"</span>,[netlocID[<span class="number">0</span>], _urlparse[<span class="number">2</span>], _urlparse[<span class="number">4</span>], <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    con.commit()</span><br><span class="line">    print(cur.lastrowid, netlocID)</span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    cur.execute(<span class="string">'''</span></span><br><span class="line"><span class="string">        SELECT table1.id, table2.netloc, table1.path, table1.param, table1.depth, table2.id</span></span><br><span class="line"><span class="string">        FROM table1</span></span><br><span class="line"><span class="string">        JOIN table2</span></span><br><span class="line"><span class="string">            ON table1.table2_id=table2.id</span></span><br><span class="line"><span class="string">        WHERE table1.seen = FALSE and table1.depth &lt; 3</span></span><br><span class="line"><span class="string">        ORDER BY table1.date ASC</span></span><br><span class="line"><span class="string">        LIMIT 0, 1;</span></span><br><span class="line"><span class="string">    '''</span>)</span><br><span class="line">    seed = cur.fetchone()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> seed <span class="keyword">or</span> i &gt; <span class="number">1000</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    cur .execute(<span class="string">'''</span></span><br><span class="line"><span class="string">        UPDATE table1</span></span><br><span class="line"><span class="string">        SET seen = TRUE</span></span><br><span class="line"><span class="string">        WHERE id = ?</span></span><br><span class="line"><span class="string">    '''</span>, [seed[<span class="number">0</span>]])</span><br><span class="line">    con.commit()</span><br><span class="line"></span><br><span class="line">    baseURL= <span class="string">"&#123;0&#125;&#123;1&#125;?&#123;2&#125;"</span>.format(seed[<span class="number">1</span>],seed[<span class="number">2</span>],seed[<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> parseURL(baseURL):</span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> [_.find_parent()[<span class="string">"href"</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> dom.select(<span class="string">".LC20lb"</span>)]:</span><br><span class="line">            _urlparse = requests.compat.urlparse(href)</span><br><span class="line">            netloc = <span class="string">"://"</span>.join(_urlparse[:<span class="number">2</span>])</span><br><span class="line">            cur.execute(<span class="string">"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1"</span>, [netloc]) <span class="comment">#netloc을 시퀀스로 만들어서 넘겨줘야함</span></span><br><span class="line"></span><br><span class="line">            netlocID = cur.fetchone()</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> netlocID:</span><br><span class="line">                cur.execute(<span class="string">"INSERT INTO table2(netloc) VALUES(?)"</span>, [netloc])</span><br><span class="line"></span><br><span class="line">                con.commit()</span><br><span class="line"></span><br><span class="line">                cur.execute(<span class="string">"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1"</span>, [netloc])</span><br><span class="line"></span><br><span class="line">                netlocID = cur.fetchone()</span><br><span class="line"></span><br><span class="line">            cur.execute(<span class="string">"INSERT INTO table1(table2_id, path, param, depth, inbound) VALUES(?, ?, ?, ?, ?)"</span>,[netlocID[<span class="number">0</span>], _urlparse[<span class="number">2</span>], _urlparse[<span class="number">4</span>], seed[<span class="number">4</span>]+<span class="number">1</span>, seed[<span class="number">5</span>]])</span><br><span class="line">            con.commit()</span><br><span class="line"></span><br><span class="line"><span class="comment">#     break</span></span><br></pre></td></tr></table></figure>


<p><img src="https://user-images.githubusercontent.com/33630505/61233463-95ea2480-a76b-11e9-9fc1-c8a5e1ff520a.JPG" alt="sequence"><br><img src="https://user-images.githubusercontent.com/33630505/61232837-2de70e80-a76a-11e9-8571-9d2fcf5d90a9.JPG" alt="table1"><br><img src="https://user-images.githubusercontent.com/33630505/61232839-2e7fa500-a76a-11e9-8224-bfdb39180664.JPG" alt="table2"></p>
<p><a id = "scraping"></a></p>
<h2 id="Scraping"><a href="#Scraping" class="headerlink" title="Scraping"></a>Scraping</h2><blockquote>
<p>Crawling한 url로 부터 내가 원하는 데이터를 수집하는 것을 말한다</p>
</blockquote>
<br>

<h3 id="Naver-news-본문-scraping-예제-Dynamic-HTML-X"><a href="#Naver-news-본문-scraping-예제-Dynamic-HTML-X" class="headerlink" title="Naver news 본문 scraping 예제 (Dynamic HTML X)"></a>Naver news 본문 scraping 예제 (Dynamic HTML X)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> download</span><br><span class="line"></span><br><span class="line">driver = webdriver.Chrome(<span class="string">"크롬드라이버 경로"</span>)</span><br><span class="line">driver.get(<span class="string">"https://news.naver.com/"</span>)</span><br><span class="line"></span><br><span class="line">dom = BeautifulSoup(driver.page_source, <span class="string">'lxml'</span>)</span><br><span class="line"><span class="comment"># crawling으로 url 확보 했다고 가정</span></span><br><span class="line">urls=[x[<span class="string">'href'</span>] <span class="keyword">for</span> x <span class="keyword">in</span> dom.select(<span class="string">"#main_content a"</span>) <span class="keyword">if</span> len(x[<span class="string">'href'</span>]) &gt; <span class="number">7</span> <span class="keyword">and</span> <span class="string">'read'</span> <span class="keyword">in</span> x[<span class="string">'href'</span>]][<span class="number">7</span>:]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseContent</span><span class="params">(url)</span>:</span>   <span class="comment"># crawling한 url을 인자로 전달하면 제목, 본문내용 parsing</span></span><br><span class="line">    html = download.download(<span class="string">"get"</span>, url)</span><br><span class="line">    dom = download.BeautifulSoup(html.text, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">"title"</span>: dom.select_one(<span class="string">"#articleTitle"</span>).text.strip(),</span><br><span class="line">            <span class="string">"body"</span>: dom.select_one(<span class="string">"#articleBodyContents"</span>).text.strip()</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">contents = list()</span><br><span class="line"><span class="keyword">while</span> urls:                <span class="comment"># urls안에 있는 url이 없을때 까지 계속 parsing</span></span><br><span class="line">    baseURL = urls.pop(<span class="number">0</span>)</span><br><span class="line">    contents.append(parseContent(baseURL))        </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">con = sqlite3.connect(<span class="string">"news.db"</span>)</span><br><span class="line">cur = con.cursor()</span><br><span class="line"></span><br><span class="line">cur.execute(<span class="string">"""</span></span><br><span class="line"><span class="string">    CREATE TABLE news(</span></span><br><span class="line"><span class="string">        title TEXT NOT NULL,</span></span><br><span class="line"><span class="string">        content TEXT NOT NULL</span></span><br><span class="line"><span class="string">    );</span></span><br><span class="line"><span class="string">"""</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> contents:     <span class="comment"># parsing한 data DB에 저장하기</span></span><br><span class="line">    content=contents.pop(<span class="number">0</span>)</span><br><span class="line">    cur.execute(<span class="string">"""</span></span><br><span class="line"><span class="string">        INSERT INTO news</span></span><br><span class="line"><span class="string">        (title, content)</span></span><br><span class="line"><span class="string">        VALUES(?, ?)</span></span><br><span class="line"><span class="string">    """</span>, [content[<span class="string">'title'</span>], content[<span class="string">'body'</span>]])</span><br><span class="line">    con.commit()</span><br></pre></td></tr></table></figure>

<br>

<h2 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h2><blockquote>
<p>Web Browser Automation</p>
</blockquote>
<p><strong>단점</strong> page rendering중에는 dom객체에 접근하지 못하고 에러가 날 수 있다. 그래서 time sleep으로 시간을 부여하여 에러 발생 가능성을 줄이고 에러 핸들링이 필요하다. 결국 selenium을 활용하면 오히려 시간이 오래걸릴 수 있다.<br>{: .notice}</p>
<br>

<h3 id="Dynamic-HTML-Scraping-예제"><a href="#Dynamic-HTML-Scraping-예제" class="headerlink" title="Dynamic HTML Scraping 예제"></a>Dynamic HTML Scraping 예제</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">driver = webdriver.Chrome(<span class="string">"chromedriver.exe 경로"</span>)  <span class="comment"># driver를 생성하면 chrome 브라우저 창 생성</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">html_parser</span><span class="params">(url)</span>:</span></span><br><span class="line">    driver.get(url)</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    html = driver.page_source</span><br><span class="line">    dom = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    resp=dom.select(<span class="string">'#main'</span>)</span><br><span class="line">    <span class="keyword">return</span> resp</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(url, country)</span>:</span></span><br><span class="line">    driver.get(url)</span><br><span class="line">    inputTag = driver.find_element_by_css_selector(<span class="string">"#search_term"</span>)</span><br><span class="line">    inputTag.send_keys(country)</span><br><span class="line">    driver.find_element_by_css_selector(<span class="string">"#search"</span>).click()</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    html = driver.page_source</span><br><span class="line">    dom = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [requests.compat.urljoin(url, _[<span class="string">'href'</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> dom.select(<span class="string">"#results a"</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nation = search(<span class="string">"http://example.webscraping.com/places/default/search"</span>, <span class="string">"korea"</span>)</span><br><span class="line"></span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">while</span> nation:</span><br><span class="line">    baseURL = nation.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    dom=html_parser(baseURL)</span><br><span class="line">    result.append(dom[<span class="number">0</span>].text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> result:</span><br><span class="line">    print(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">National Flag:</span><br><span class="line">Area: <span class="number">120</span>,<span class="number">540</span> square kilometres</span><br><span class="line">Population: <span class="number">22</span>,<span class="number">912</span>,<span class="number">177</span></span><br><span class="line">Iso: KP</span><br><span class="line">Country: North Korea</span><br><span class="line">Capital: Pyongyang</span><br><span class="line">Continent: AS</span><br><span class="line">Tld: .kp</span><br><span class="line">Currency Code: KPW</span><br><span class="line">Currency Name: Won</span><br><span class="line">Phone: <span class="number">850</span></span><br><span class="line">Postal Code Format: <span class="comment">###-###</span></span><br><span class="line">Postal Code Regex: ^(\d&#123;<span class="number">6</span>&#125;)$</span><br><span class="line">Languages: ko-KP</span><br><span class="line">Neighbours: CN KR RU</span><br><span class="line">Edit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">National Flag:</span><br><span class="line">Area: <span class="number">98</span>,<span class="number">480</span> square kilometres</span><br><span class="line">Population: <span class="number">48</span>,<span class="number">422</span>,<span class="number">644</span></span><br><span class="line">Iso: KR</span><br><span class="line">Country: South Korea</span><br><span class="line">Capital: Seoul</span><br><span class="line">Continent: AS</span><br><span class="line">Tld: .kr</span><br><span class="line">Currency Code: KRW</span><br><span class="line">Currency Name: Won</span><br><span class="line">Phone: <span class="number">82</span></span><br><span class="line">Postal Code Format: SEOUL <span class="comment">###-###</span></span><br><span class="line">Postal Code Regex: ^(?:SEOUL)*(\d&#123;6&#125;)$</span><br><span class="line">Languages: ko-KR,en</span><br><span class="line">Neighbours: KP</span><br><span class="line">Edit</span><br><span class="line"></span><br><span class="line">driver.close() <span class="comment"># 브라우저 창 닫기</span></span><br></pre></td></tr></table></figure>

<br>

<h2 id="Page-Rank"><a href="#Page-Rank" class="headerlink" title="Page Rank"></a>Page Rank</h2><p>Page Rank 참고: <a href="https://sungmooncho.com/2012/08/26/pagerank/" target="_blank" rel="noopener">sungmooncho</a><br></p>

          
        </div>
        
          <br>
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2021-12-29T12:24:01+09:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>Dec 29, 2021</p>
    <!-- __('post.updated') + ' ' +  -->
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/data-mining/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>data mining</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/crawling/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>crawling</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/scraping/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>scraping</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/page-rank/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>page rank</p></a></div>


        
      
    </div>
  </section>


        

        
            <div class="prev-next">
                
                    <section class="prev">
                        <span class="art-item-left">
                            <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;prev</h6>
                            <h4>
                                <a href="/2019/07/20/nlp/" rel="prev" title="NLP(자연어 처리)">
                                  
                                      NLP(자연어 처리)
                                  
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/NLP/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> NLP</a> <a class="tag" href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> 자연어 처리</a>
                                </h6>
                            
                        </span>
                    </section>
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/2019/07/13/objectModel/" rel="prev" title="Object Model">
                                    
                                        Object Model
                                    
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/object-model/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> object model</a> <a class="tag" href="/tags/dom/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> dom</a> <a class="tag" href="/tags/bom/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> bom</a> <a class="tag" href="/tags/javascript/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> javascript</a>
                                </h6>
                            
                        </span>
                    </section>
                
            </div>
        
      </section>
      <!-- Google AdSense -->
      <!-- In post -->
      <script data-ad-client="ca-pub-1288998211050792" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Google AdSense -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1288998211050792"
     data-ad-slot="5437821794"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  


  







  <script>
    window.subData = {
      title: 'Data Collection',
      tools: true
    }
  </script>


  <div id="disqus_thread"></div>
</div>
<aside class='l_side'>
  
    
    
      
        
          <section class='widget blogger'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='/jh.jpg'/>
      </div>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:wlgur278@gmail.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/Jungjihyuk"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
  </div>
</section>

        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
      
        
      
        
          
  <section class='widget toc-wrapper'>
    <header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Shortcuts</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-수집-종류"><span class="toc-text">Data 수집 종류</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Web-Crawling은-불법"><span class="toc-text">Web Crawling은 불법?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#어떤-것이-합법인가"><span class="toc-text">어떤 것이 합법인가?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Opt-in-vs-Opt-out"><span class="toc-text">Opt-in vs Opt-out</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-from-Portal-site-Web-Data"><span class="toc-text">Data from Portal site(Web Data)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Crawling부터-DB-저장까지-Flow"><span class="toc-text">Crawling부터 DB 저장까지 Flow</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-mining"><span class="toc-text">Data mining</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Crawling-vs-Scraping"><span class="toc-text">Crawling vs Scraping</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Crawling"><span class="toc-text">Crawling</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BFS-Crawling"><span class="toc-text">BFS Crawling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DFS-Crawling-Focused-Crawling"><span class="toc-text">DFS Crawling(Focused Crawling)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Crawling-한-url-DB에-저장하기"><span class="toc-text">Crawling 한 url DB에 저장하기</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scraping"><span class="toc-text">Scraping</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Naver-news-본문-scraping-예제-Dynamic-HTML-X"><span class="toc-text">Naver news 본문 scraping 예제 (Dynamic HTML X)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Selenium"><span class="toc-text">Selenium</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Dynamic-HTML-Scraping-예제"><span class="toc-text">Dynamic HTML Scraping 예제</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Page-Rank"><span class="toc-text">Page Rank</span></a></li></ol>
    </div>
  </section>


        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
      
        
      
        
      
        
          
  <section class='widget category'>
    <header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;category</div>
  
    <a class="rightBtn"
    
      rel="external nofollow noopener noreferrer"
    
    
      target="_self"
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/AI/" href="/categories/AI/"><div class='name'>AI</div><div class='badge'>(10)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Data-Analysis/" href="/categories/AI/Data-Analysis/"><div class='name'>Data Analysis</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Deep-Learning/" href="/categories/AI/Deep-Learning/"><div class='name'>Deep Learning</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Machine-Learning/" href="/categories/AI/Machine-Learning/"><div class='name'>Machine Learning</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Natural-Language-Processing/" href="/categories/AI/Natural-Language-Processing/"><div class='name'>Natural Language Processing</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Numpy/" href="/categories/AI/Numpy/"><div class='name'>Numpy</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Pandas/" href="/categories/AI/Pandas/"><div class='name'>Pandas</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Python/" href="/categories/AI/Python/"><div class='name'>Python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Algorithm/" href="/categories/Algorithm/"><div class='name'>Algorithm</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Algorithm/Arrays/" href="/categories/Algorithm/Arrays/"><div class='name'>Arrays</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Data-Structure/" href="/categories/Data-Structure/"><div class='name'>Data Structure</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/English/" href="/categories/English/"><div class='name'>English</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Git/" href="/categories/Git/"><div class='name'>Git</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/IT-Terms/" href="/categories/IT-Terms/"><div class='name'>IT Terms</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/JSP-Servlet/" href="/categories/JSP-Servlet/"><div class='name'>JSP & Servlet</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Language/" href="/categories/Language/"><div class='name'>Language</div><div class='badge'>(8)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Language/Java/" href="/categories/Language/Java/"><div class='name'>Java</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Language/Markup-Language/" href="/categories/Language/Markup-Language/"><div class='name'>Markup Language</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Language/Python/" href="/categories/Language/Python/"><div class='name'>Python</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Web/" href="/categories/Web/"><div class='name'>Web</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Bootstrap4/" href="/categories/Web/Bootstrap4/"><div class='name'>Bootstrap4</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Django/" href="/categories/Web/Django/"><div class='name'>Django</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Flask/" href="/categories/Web/Flask/"><div class='name'>Flask</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Object-Model/" href="/categories/Web/Object-Model/"><div class='name'>Object Model</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Objectoriented/" href="/categories/Web/Objectoriented/"><div class='name'>Objectoriented</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
      
        
      
        
      
        
      
        
          
  <section class='widget tagcloud'>
    <header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Keywords</div>
  
    <a class="rightBtn"
    
      rel="external nofollow noopener noreferrer"
    
    
      target="_self"
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/AI/" style="font-size: 22px; color: #636363">AI</a> <a href="/tags/Algorithm/" style="font-size: 14px; color: #999">Algorithm</a> <a href="/tags/CodeSignal/" style="font-size: 16px; color: #8b8b8b">CodeSignal</a> <a href="/tags/CodeSignal2/" style="font-size: 14px; color: #999">CodeSignal2</a> <a href="/tags/Data-Analysis/" style="font-size: 14px; color: #999">Data Analysis</a> <a href="/tags/Deep-Learning/" style="font-size: 16px; color: #8b8b8b">Deep Learning</a> <a href="/tags/Django/" style="font-size: 14px; color: #999">Django</a> <a href="/tags/EDA/" style="font-size: 14px; color: #999">EDA</a> <a href="/tags/Flask/" style="font-size: 14px; color: #999">Flask</a> <a href="/tags/FrontEnd/" style="font-size: 14px; color: #999">FrontEnd</a> <a href="/tags/Git/" style="font-size: 14px; color: #999">Git</a> <a href="/tags/Git-Flow/" style="font-size: 14px; color: #999">Git-Flow</a> <a href="/tags/Github/" style="font-size: 14px; color: #999">Github</a> <a href="/tags/Gitlab/" style="font-size: 14px; color: #999">Gitlab</a> <a href="/tags/IT/" style="font-size: 14px; color: #999">IT</a> <a href="/tags/Java/" style="font-size: 14px; color: #999">Java</a> <a href="/tags/Jsp/" style="font-size: 14px; color: #999">Jsp</a> <a href="/tags/Lecture/" style="font-size: 22px; color: #636363">Lecture</a> <a href="/tags/Machine-Learning/" style="font-size: 16px; color: #8b8b8b">Machine Learning</a> <a href="/tags/NLP/" style="font-size: 14px; color: #999">NLP</a> <a href="/tags/Numpy/" style="font-size: 14px; color: #999">Numpy</a> <a href="/tags/Pandas/" style="font-size: 14px; color: #999">Pandas</a> <a href="/tags/Programming/" style="font-size: 14px; color: #999">Programming</a> <a href="/tags/Python/" style="font-size: 16px; color: #8b8b8b">Python</a> <a href="/tags/Servlet/" style="font-size: 14px; color: #999">Servlet</a> <a href="/tags/Web/" style="font-size: 14px; color: #999">Web</a> <a href="/tags/algorithm/" style="font-size: 20px; color: #707070">algorithm</a> <a href="/tags/api/" style="font-size: 14px; color: #999">api</a> <a href="/tags/array/" style="font-size: 14px; color: #999">array</a> <a href="/tags/bom/" style="font-size: 14px; color: #999">bom</a> <a href="/tags/bootstrap/" style="font-size: 14px; color: #999">bootstrap</a> <a href="/tags/class/" style="font-size: 14px; color: #999">class</a> <a href="/tags/clean-code/" style="font-size: 14px; color: #999">clean code</a> <a href="/tags/coding-test/" style="font-size: 14px; color: #999">coding test</a> <a href="/tags/crawling/" style="font-size: 14px; color: #999">crawling</a> <a href="/tags/css/" style="font-size: 14px; color: #999">css</a> <a href="/tags/data-mining/" style="font-size: 14px; color: #999">data mining</a> <a href="/tags/database/" style="font-size: 16px; color: #8b8b8b">database</a> <a href="/tags/deep-learning/" style="font-size: 16px; color: #8b8b8b">deep learning</a> <a href="/tags/deque/" style="font-size: 14px; color: #999">deque</a> <a href="/tags/dom/" style="font-size: 14px; color: #999">dom</a> <a href="/tags/generator/" style="font-size: 14px; color: #999">generator</a> <a href="/tags/git/" style="font-size: 14px; color: #999">git</a> <a href="/tags/helper-function/" style="font-size: 14px; color: #999">helper function</a> <a href="/tags/iris/" style="font-size: 14px; color: #999">iris</a> <a href="/tags/javascript/" style="font-size: 14px; color: #999">javascript</a> <a href="/tags/js/" style="font-size: 14px; color: #999">js</a> <a href="/tags/json/" style="font-size: 14px; color: #999">json</a> <a href="/tags/neural-network/" style="font-size: 14px; color: #999">neural network</a> <a href="/tags/object/" style="font-size: 14px; color: #999">object</a> <a href="/tags/object-model/" style="font-size: 14px; color: #999">object model</a> <a href="/tags/page-rank/" style="font-size: 14px; color: #999">page rank</a> <a href="/tags/python/" style="font-size: 24px; color: #555">python</a> <a href="/tags/queue/" style="font-size: 14px; color: #999">queue</a> <a href="/tags/scraping/" style="font-size: 14px; color: #999">scraping</a> <a href="/tags/send/" style="font-size: 14px; color: #999">send</a> <a href="/tags/stack/" style="font-size: 14px; color: #999">stack</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #999">tensorflow</a> <a href="/tags/xml/" style="font-size: 14px; color: #999">xml</a> <a href="/tags/yield/" style="font-size: 14px; color: #999">yield</a> <a href="/tags/%EB%AA%85%EB%A0%B9%EC%96%B4/" style="font-size: 14px; color: #999">명령어</a> <a href="/tags/%EB%AC%B8%EB%B2%95/" style="font-size: 14px; color: #999">문법</a> <a href="/tags/%EB%B0%B1%EC%A4%80/" style="font-size: 14px; color: #999">백준</a> <a href="/tags/%EC%82%B0%ED%83%80-%ED%86%A0%EC%9D%B5/" style="font-size: 14px; color: #999">산타 토익</a> <a href="/tags/%EC%84%A4%EA%B3%84/" style="font-size: 14px; color: #999">설계</a> <a href="/tags/%EC%8B%9C%EC%9B%90%EC%8A%A4%EC%BF%A8/" style="font-size: 14px; color: #999">시원스쿨</a> <a href="/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/" style="font-size: 14px; color: #999">알고리즘</a> <a href="/tags/%EC%98%81%EC%96%B4/" style="font-size: 16px; color: #8b8b8b">영어</a> <a href="/tags/%EC%9A%A9%EC%96%B4/" style="font-size: 14px; color: #999">용어</a> <a href="/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/" style="font-size: 14px; color: #999">자료구조</a> <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/" style="font-size: 14px; color: #999">자연어 처리</a> <a href="/tags/%EC%A0%95%EB%A6%AC/" style="font-size: 18px; color: #7e7e7e">정리</a> <a href="/tags/%EC%BD%94%EB%94%A9%EC%97%B0%EC%8A%B5/" style="font-size: 18px; color: #7e7e7e">코딩연습</a> <a href="/tags/%ED%86%A0%EC%9D%B5/" style="font-size: 14px; color: #999">토익</a> <a href="/tags/%ED%95%9C%EB%88%88%EC%97%90-%EB%B3%B4%EA%B8%B0/" style="font-size: 16px; color: #8b8b8b">한눈에 보기</a> <a href="/tags/%ED%95%9C%EB%88%88%EC%97%90-%EC%A0%95%EB%A6%AC/" style="font-size: 14px; color: #999">한눈에 정리</a> <a href="/tags/%ED%98%91%EC%97%85/" style="font-size: 14px; color: #999">협업</a> <a href="/tags/%ED%9A%8C%ED%99%94/" style="font-size: 14px; color: #999">회화</a>
    </div>
  </section>


        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
  
  <!-- Google AdSense -->
  <div style="margin-top: 16px;">

  </div>
  <script data-ad-client="ca-pub-1288998211050792" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Google AdSense -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1288998211050792"
     data-ad-slot="7750297977"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

<footer class="clearfix">
  
    <div class="social-wrapper">
      
        
          <a href="mailto:wlgur278@gmail.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/Jungjihyuk"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <!-- <div><- markdown(__('footer.license')) </div> -->
  <div>
    <!-- <- __('footer.use')  -->
    <!-- a href = "<- theme.info.docs " -->
    <span>Copyright. </span>
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material-X</a>
    <!-- <- theme.info.name    -->
    <!-- <- __('footer.theme')  -->
    <br>
    
    . 
  </div>
  
</footer>
<script>setLoadingBarProgress(80);</script>

<script>

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-jungjihyuk-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>

      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>

<script async src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>

  <script async src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>
  <script async src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>





  
  
  
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["unsplash.jpg", "jonathan.jpg", "flower.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["unsplash.jpg", "jonathan.jpg", "flower.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  











  
<script src="/js/app.js"></script>



  
<script src="/js/search.js"></script>



  
    
<script src="/js/commentTyping.js"></script>

  





<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
