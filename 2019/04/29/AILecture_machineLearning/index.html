<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>AI 이노베이션 스퀘어 수업(기본반) - machine learning | 지혁&#39;s Blog</title>
  
  

  
  <link rel="alternate" href="/feed.xml" title="지혁's Blog">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- Auto Canonical -->
  <link rel="canonical" href="http://jungjihyuk.github.io/2019/04/29/ailecture_machinelearning/"/>

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  
    
<link rel="stylesheet" href="/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  

  <!-- Google AdSense -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143236286-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-143236286-2');
</script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/feed.xml" title="지혁's Blog" type="application/rss+xml">
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>Imitation, Imagination, Integration</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="search" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;Home
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/about"
            
              rel="nofollow"
            
            
            id="about">
            <i class='fas fa-info-circle fa-fw'></i>&nbsp;About
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" target="_self" href='/' >
        
          지혁's Blog
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/"
                  
                  
                    target="_self"
                  
                  id="home">
									<i class='fas fa-grin fa-fw'></i>&nbsp;Home
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives"
                  
                    rel="nofollow"
                  
                  
                    target="_self"
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;Archives
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;Home
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;Archives
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/projects"
                
                
                id="projects">
								<i class='fas fa-code-branch fa-fw'></i>&nbsp;Projects
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="https://xaoxuu.com/wiki/material-x/"
                
                  rel="nofollow"
                
                
                id="https:xaoxuu.comwikimaterial-x">
								<i class='fas fa-book fa-fw'></i>&nbsp;Reference
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/about"
                
                  rel="nofollow"
                
                
                id="about">
								<i class='fas fa-info-circle fa-fw'></i>&nbsp;About
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  
    <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2019/04/29/AILecture_machineLearning/">
        AI 이노베이션 스퀘어 수업(기본반) - machine learning
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="http://jungjihyuk.github.io" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>Jihyuk Jung</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-04-29</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/AI/Machine-Learning/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>AI&nbsp;/&nbsp;Machine Learning</p>
    </a>
  </div>


          
        
          
            
  


          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <p><a id = '21th'></a></p>
<h1 id="2019년-6월-4일-화요일-21th"><a href="#2019년-6월-4일-화요일-21th" class="headerlink" title="2019년 6월 4일 화요일 21th"></a>2019년 6월 4일 화요일 21th</h1><h2 id="기계학습-분류"><a href="#기계학습-분류" class="headerlink" title="기계학습 분류"></a>기계학습 분류</h2><p><img src="https://user-images.githubusercontent.com/33630505/59347252-1eca0680-8d4f-11e9-9104-a788a22a72e3.JPG" alt="learning model"></p>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">지도 학습</span> <br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">정답을 알려주며 학습시킨다.</span><br><span class="line">예를 들어 &#39;바퀴 4개, 문짝 4개, 도로위를 시속 0~200km(input data) 달릴 수 있는 것은 자동차(label data or target data)야&#39;</span><br><span class="line">라고 학습 시키고 학습을 바탕으로 모델이 예측할 수 있도록 하는 방법이다.</span><br><span class="line"></span><br><span class="line">지도학습은 크게 Classification, Regression으로 나눈다.</span><br><span class="line">Classification은 또 이진분류, 다중분류로 볼 수 있다.</span><br><span class="line">이진분류 같은 경우 생존자 or 비생존자와 같이 둘 중 하나로 분류 가능한 것을 말한다.</span><br><span class="line">LogisticRegression 알고리즘이 대표적인 이진 분류 알고리즘이다.</span><br><span class="line">다중 분류는 어떤 데이터에 대해 여러 값 중 하나로 분류 가능한 것을 말한다.</span><br><span class="line">예를 들어 축구공, 야구공, 농구공 등 Label data가 여러개로 나뉠 수 있는 경우를 말한다.</span><br><span class="line">이때는 KNN알고리즘으로 분류 가능하다.</span><br><span class="line">KNN알고리즘은 데이터가 많아지거나 Label data가 많아지면 성능이 떨어질 가능성이 높다.</span><br><span class="line"></span><br><span class="line">Regression는 어떤 데이터들의 특징을 토대로 값을 예측하는 것을 말한다.</span><br><span class="line">예를 들어 키가 170cm인 사람의 몸무게는 65kg이다와 같이 Label data가 실수 값을 갖거나</span><br><span class="line">연속적, 범위가 정해지지 않은 경우 무한대인 경우이다.</span><br><span class="line"></span><br><span class="line">분류인지 회귀인지는 label data가 유한개인지 무한개인지 생각해보면 된다.</span><br></pre></td></tr></table></figure>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">비지도 학습</span> <br>        </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">정답을 알려주지 않고 비슷한 데이터들 끼리 군집화하여 학습한다.</span><br><span class="line">예를 들어 &#39;남자, 여자 사진을 무작위로 입력값으로 줬을 때 사진을 보고 공통적으로 보이는</span><br><span class="line">특성들을 찾아 비슷한 특성끼리 묶어 남자, 여자를 학습 시킨 데이터를 기반으로 분류하는 것을 말한다.</span><br><span class="line"></span><br><span class="line">비지도학습은 크게 Clustering, Visualization &amp; Dimensionality  Reduction, Association으로 나뉜다.</span><br><span class="line">Clustering은 비슷한 것끼리 묶는 방법이다.</span><br><span class="line">Clustering 방법중 대표적인 알고리즘인 k-means는 예를 들어 3가지로 묶는다고 했을 때 데이터에서 무작위로 임의의 값을 3개 찍고</span><br><span class="line">랜덤한 데이터 값에서 가까운 값을 찾아 평균을 낸다. 그러면 평균낸 값에서 가까운 값을 또 찾고 그 값에서 평균을 낸다.</span><br><span class="line">이와 같은 작업을 반복하여 평균값이 변하지 않는 때를 찾아 그 평균 값을 기준으로 군집화 하면 그것이 클러스터링 방법이다.</span><br><span class="line"></span><br><span class="line">Visualization &amp; Dimensionality  Reduction은 데이터간의 상관성을 분석하여 포함시키지 않아도 예측하는데 큰 지장 없는</span><br><span class="line">데이터 열을 줄임으로써 차원을 축소하는 방법이다.</span><br><span class="line">대표적으로 pca 방법이 있다. pca알고리즘은 데이터 분포에서 variance가 큰 방향의 벡터에 데이터를 정사영하여</span><br><span class="line">차원을 축소시킨다. 이렇게 했을 때 데이터의 구조는 크게 바뀌지 않으면서 차원은 감소시킬수 있기 때문이다.</span><br><span class="line"></span><br><span class="line">Association은 유사한 요소를 찾아 묶는 것이다. 이때 유사성을 파악할때 데이터간의 차이를 측정하는 방법인</span><br><span class="line">유클리드 거리 측정 방법과 비-유클리드 거리 측정법으로 나눌 수 있다.</span><br><span class="line">예를 들어 &#39;근처에 사는 사람은 비슷한 성격을 갖고 있을 것이다&#39; 처럼 묶거나</span><br><span class="line">&#39;피자를 사는 사람은 꼭 콜라를 산다&#39; 처럼 묶을 수 있다.</span><br></pre></td></tr></table></figure>

<p>지도학습, 비지도학습 : <a href="https://marobiana.tistory.com/155" target="_blank" rel="noopener">tistory</a> <br><br>차원 축소 (pca): <a href="https://excelsior-cjh.tistory.com/167" target="_blank" rel="noopener">tistory</a>, &nbsp; <a href="https://wikidocs.net/7646" target="_blank" rel="noopener">wikidocs</a> <br></p>
<h2 id="기계학습-목적"><a href="#기계학습-목적" class="headerlink" title="기계학습 목적"></a>기계학습 목적</h2><p><span  style="color: red; font-size:30px;">Data</span><strong>로 부터</strong> <br><br><span  style="color: red; font-size:30px;">Specific</span><strong>문제</strong> <span  style="color: red; font-size:30px">해결</span><strong>을 위한</strong> <br><br><span  style="color: red; font-size:30px;">최적의 모델</span> <strong>만들기</strong></p>
<h2 id="Data수집부터-예측까지-과정"><a href="#Data수집부터-예측까지-과정" class="headerlink" title="Data수집부터 예측까지 과정"></a>Data수집부터 예측까지 과정</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">0. Data 불러들이기</span><br><span class="line">- 적합한 데이터 format으로 변환</span><br><span class="line">1. Tidy data인지 확인하기</span><br><span class="line">2. info</span><br><span class="line">- missing datat 체크 (mino.matrix)</span><br><span class="line">- object, category type은 숫자 타입으로 변환</span><br><span class="line">- 차원의 저주 (필요없는 열 삭제)</span><br><span class="line">- 데이터 갯수 확인 (데이터 갯수가 충분한가)</span><br><span class="line">- 메모리 크기 확인 (내가 불러들일 수 있는 사이즈인가)</span><br><span class="line">- label(target,class) data 포함 여부 확인</span><br><span class="line">3. describe</span><br><span class="line">- 지도학습을 하는 경우 pairplot으로 분류 가능한지 확인</span><br><span class="line">- label data가 유한개인지 무한개인지 확인</span><br><span class="line">- label data 유한 --&gt; classifications</span><br><span class="line">- label data 무한 --&gt; regression</span><br><span class="line">- 상관성 확인해야 하는 경우 heatmap</span><br><span class="line">- boxplot</span><br><span class="line">- 비지도학습을 하는 경우 label data가 없이 즉, 기준이되는 답이 없이 학습해야함.</span><br><span class="line">- 비지도학습의 경우 클러스터링, 시각화와 차원축소, 연관 규칙 학습등의 알고리즘을 사용</span><br><span class="line">4. 왜도, 첨도</span><br><span class="line">- skew</span><br><span class="line">- kurtosis</span><br><span class="line">5. 5총사중 나머지 3개 (head, tail, sample)</span><br><span class="line">6. 목적에 맞게 평가 척도에 따라 최적의 모델 생성</span><br><span class="line">7. 성능 테스트</span><br></pre></td></tr></table></figure>


<h2 id="label이-유한일때-무한일때"><a href="#label이-유한일때-무한일때" class="headerlink" title="label이 유한일때, 무한일때"></a>label이 유한일때, 무한일때</h2><h3 id="유한일때"><a href="#유한일때" class="headerlink" title="유한일때"></a>유한일때</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">iris = sns.load_dataset(<span class="string">'iris'</span>)</span><br><span class="line">iris</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/58871405-e138fe00-86fc-11e9-87a6-f7f31a8a8ca0.JPG" alt="iris"></p>
<h3 id="무한일때"><a href="#무한일때" class="headerlink" title="무한일때"></a>무한일때</h3><blockquote>
<p>mpg(연비)를 예측한다고 가정했을 때 연비는 정해져 있는 label이 아니기 때문에 무한 label임으로 regression 즉, 연속된 값을 예측해야 한다.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">mpg = sns.load_dataset(<span class="string">'mpg'</span>)</span><br><span class="line">mpg</span><br></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/33630505/58871406-e138fe00-86fc-11e9-94e0-c1ec9499cbd8.JPG" alt="mpg"></p>
<h2 id="masking-기법으로-missing-data-보기"><a href="#masking-기법으로-missing-data-보기" class="headerlink" title="masking 기법으로 missing data 보기"></a>masking 기법으로 missing data 보기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">mpg = sns.load_dataset(<span class="string">'mpg'</span>)</span><br><span class="line">mpg.horsepower[mpg.horsepower.isnull()] <span class="comment"># or mpg.horsepower[mpg.horsepower.isna()]</span></span><br><span class="line"></span><br><span class="line">:</span><br><span class="line"><span class="number">32</span>    NaN</span><br><span class="line"><span class="number">126</span>   NaN</span><br><span class="line"><span class="number">330</span>   NaN</span><br><span class="line"><span class="number">336</span>   NaN</span><br><span class="line"><span class="number">354</span>   NaN</span><br><span class="line"><span class="number">374</span>   NaN</span><br></pre></td></tr></table></figure>

<h2 id="missing-data-그래프로-확인하기"><a href="#missing-data-그래프로-확인하기" class="headerlink" title="missing data 그래프로 확인하기"></a>missing data 그래프로 확인하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip install missingno</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> missingno <span class="keyword">as</span> mino</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">mpg = sns.load_dataset(<span class="string">'mpg'</span>)</span><br><span class="line">mino.matrix(mpg)</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/58872893-fb281000-86ff-11e9-8a18-258b12ba14d1.JPG" alt="mino"></p>
<blockquote>
<p>data의 양이 충분하지 않을때 missing data가 있으면 적당한 값으로 채워 넣어 성능을 높여주고,<br>적당한 값을 채우기 애매할 때는 missing data가 있는 row를 지워야 한다.</p>
</blockquote>
<h2 id="데이터를-쪼개-성능-비교하기"><a href="#데이터를-쪼개-성능-비교하기" class="headerlink" title="데이터를 쪼개 성능 비교하기"></a>데이터를 쪼개 성능 비교하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">iris = sns.load_dataset(<span class="string">'iris'</span>)</span><br><span class="line">iris.species = iris.species.map(&#123;<span class="string">'setosa'</span>: <span class="number">0</span>, <span class="string">'versicolor'</span>:<span class="number">1</span>,<span class="string">'virginica'</span>:<span class="number">2</span>&#125;)</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">iris_data = iris[iris.columns[:<span class="number">-1</span>]]</span><br><span class="line">iris[<span class="string">'species'</span>]</span><br><span class="line"></span><br><span class="line">knn.fit(iris_data, iris[<span class="string">'species'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 관례상 행렬은 대문자, 벡터는 소문자로 표기</span></span><br><span class="line">X_train, X_test, y_train , y_test = train_test_split(iris[iris.columns[:<span class="number">-1</span>]], iris.species)</span><br><span class="line">len(X_train.index)</span><br><span class="line">len(X_test.index)</span><br><span class="line">: <span class="number">112</span></span><br><span class="line">  <span class="number">38</span>    </span><br><span class="line"><span class="comment"># 75 : 25 비율로 쪼갬</span></span><br><span class="line"></span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">knn.predict(X_test)</span><br><span class="line">y_test.values</span><br><span class="line"></span><br><span class="line">: array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>], dtype=int64)</span><br><span class="line">  array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>], dtype=int64)     </span><br><span class="line"></span><br><span class="line">knn.predict(X_test) == y_test.values       </span><br><span class="line">:</span><br><span class="line">array([ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,</span><br><span class="line">        <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,</span><br><span class="line">        <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,</span><br><span class="line">        <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,</span><br><span class="line">        <span class="literal">True</span>,  <span class="literal">True</span>])</span><br><span class="line"></span><br><span class="line">confusion_matrix(y_test, knn.predict(X_test))</span><br><span class="line">:</span><br><span class="line">array([[<span class="number">10</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>, <span class="number">10</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">1</span>, <span class="number">17</span>]], dtype=int64)</span><br><span class="line"><span class="comment"># virginica를 예측한 test에서는 한번은 versicolor이라고 잘못 예측 했기 때문에 0 , 1 , 17</span></span><br></pre></td></tr></table></figure>

<p><strong>Model</strong> 학습이 끝난 알고리즘 + 데이터를 Model 이라고 한다</p>
<p><strong>복습시간</strong> 18시 50분 ~ 19시 45분 / 총 55분  </p>
<p><a id = '22th'></a></p>
<h1 id="2019년-6월-5일-수요일-22th"><a href="#2019년-6월-5일-수요일-22th" class="headerlink" title="2019년 6월 5일 수요일 22th"></a>2019년 6월 5일 수요일 22th</h1><h2 id="One-hot-encoding-amp-Label-encoding"><a href="#One-hot-encoding-amp-Label-encoding" class="headerlink" title="One hot encoding &amp; Label encoding"></a>One hot encoding &amp; Label encoding</h2><blockquote>
<p>기계학습으로 예측분석을 하기 위해서는 문자를 숫자로 변환 해야하기 때문에 Encoding을 해야한다<br>그런데 문자를 숫자로 encoding할때 성능에 영향을 미치기 때문에 상황에 따라 encoding 방식을 달리 해야 한다</p>
</blockquote>
<h3 id="One-hot-encoding"><a href="#One-hot-encoding" class="headerlink" title="One hot encoding"></a>One hot encoding</h3><blockquote>
<p>하나의 값만 True이고 나머지는 모두 False인 인코딩 방식</p>
</blockquote>
<h4 id="Scikit"><a href="#Scikit" class="headerlink" title="Scikit"></a>Scikit</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">ohe = OneHotEncoder()</span><br><span class="line">t = ohe.fit(data[[<span class="string">'species'</span>]])</span><br><span class="line">t.array()</span><br><span class="line"></span><br><span class="line">: array([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       .....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ohe.fit_transform(data[['species']]).toarray() 한번에 가능</span></span><br><span class="line"></span><br><span class="line">ohe.inverse_transform([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line">: array([[<span class="string">'setosa'</span>]], dtype=object)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 숫자로 인코딩 되기 전 문자</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Scikit’s onehotencoder의 장점은 인코딩 되기 전 문자를 알 수 있다는 것.</p>
</blockquote>
<p><span style='background-color:red'>밑의 경우에는 어떻게 해야 할까..?</span><br></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(ohe.fit_transform(data[[<span class="string">'species'</span>]]), columns=[<span class="string">'target'</span>])</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">target</span><br><span class="line"><span class="number">0</span>	(<span class="number">0</span>, <span class="number">0</span>)\t1<span class="number">.0</span></span><br><span class="line"><span class="number">1</span>	(<span class="number">0</span>, <span class="number">0</span>)\t1<span class="number">.0</span></span><br><span class="line"><span class="number">2</span>	(<span class="number">0</span>, <span class="number">0</span>)\t1<span class="number">.0</span></span><br><span class="line"><span class="number">3</span>	(<span class="number">0</span>, <span class="number">0</span>)\t1<span class="number">.0</span></span><br><span class="line"><span class="number">4</span>	(<span class="number">0</span>, <span class="number">0</span>)\t1<span class="number">.0</span></span><br><span class="line"><span class="number">5</span>	(<span class="number">0</span>, <span class="number">0</span>)\t1<span class="number">.0</span></span><br></pre></td></tr></table></figure>

<h4 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = sns.load_dataset(<span class="string">'iris'</span>)</span><br><span class="line">pd.get_dummies(data.species)</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">      setosa	   versicolor	 virginica</span><br><span class="line"><span class="number">0</span>	<span class="number">1</span>	       <span class="number">0</span>	    <span class="number">0</span></span><br><span class="line"><span class="number">1</span>	<span class="number">1</span>	       <span class="number">0</span>	    <span class="number">0</span></span><br><span class="line"><span class="number">2</span>	<span class="number">1</span>	       <span class="number">0</span>	    <span class="number">0</span></span><br><span class="line"><span class="number">3</span>	<span class="number">1</span>	       <span class="number">0</span>	    <span class="number">0</span></span><br><span class="line"><span class="number">4</span>	<span class="number">1</span>	       <span class="number">0</span>	    <span class="number">0</span></span><br><span class="line"><span class="number">5</span>	<span class="number">1</span>	       <span class="number">0</span>	    <span class="number">0</span></span><br></pre></td></tr></table></figure>


<h3 id="LabelEncoder"><a href="#LabelEncoder" class="headerlink" title="LabelEncoder"></a>LabelEncoder</h3><h4 id="Scikit-1"><a href="#Scikit-1" class="headerlink" title="Scikit"></a>Scikit</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">le.fit_transform(data.species)</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line"></span><br><span class="line">array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<h4 id="pandas-map"><a href="#pandas-map" class="headerlink" title="pandas map"></a>pandas map</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">iris = sns.load_dataset(<span class="string">'iris'</span>)</span><br><span class="line">iris.species = iris.species.map(<span class="string">'setosa'</span>: <span class="number">0</span>, <span class="string">'versicolor'</span>:<span class="number">1</span>,<span class="string">'virginica'</span>:<span class="number">2</span>&#125;)</span><br></pre></td></tr></table></figure>

<p><strong>Label encoding시 주의</strong> 거리기반 알고리즘을 사용할 때 라벨 인코딩된 값으로 학습을 하게되면 숫자간의 격차로 인해 오차가 생길 위험이 있다. 예를 들어 0, 1, 2로 라벨 인코딩 되었다고 했을 때 0과 1사이 1과 2사이는 둘다 1간격만 있어 상관 없지만 0과 2사이에는 2간격이 생겨 학습시 주의해야 한다. 따라서 label encoding 해야할 때와 하지 말아야 할때를 잘 구분해야 한다.</p>
<h2 id="Bias-Variance"><a href="#Bias-Variance" class="headerlink" title="Bias , Variance"></a>Bias , Variance</h2><p><img src="https://user-images.githubusercontent.com/33630505/58957665-fd5f9c80-87db-11e9-8094-c5ba63e4375e.JPG" alt="optimal"></p>
<blockquote>
<p>Bias가 높으면 값이 편향되어 있어서 값이 모여있고 Variance가 높으면 값이 퍼져있게된다.<br>현실에 적용할 수 있는 모델을 만들기 위해서는 Bias와 Variance가 만나는 지점을 목표로 삼고 모델을 만들어야 한다.</p>
</blockquote>
<h2 id="Trade-off"><a href="#Trade-off" class="headerlink" title="Trade off"></a>Trade off</h2><p><img src="https://user-images.githubusercontent.com/33630505/58957666-fd5f9c80-87db-11e9-9dea-1802253b3aad.JPG" alt="tradeoff"></p>
<blockquote>
<p>다양한 데이터를 학습시키지 않게 되면 bias가 높아져 정확도가 떨어지는 대신 학습하지 않은 데이터중 일부는 어쩌다 맞추는 경우는 Underfit이다.<br>다양한 데이터를 학습시키긴 했지만 데이터 양이 많지 않아 bias는 낮지만 variance가 높아 학습한 데이터에 대해서만 정확도가 높고 전혀 보지 못한 데이터에 대해서는 정확도가 현저히 낮게 되는 경우는 Overfit이다.</p>
</blockquote>
<p><span style="background-color: skyblue">Underfit의 경우 training시 정확성은 떨어지지만 test에서 오차범위가 크지 않게 예측을 할 수 있지만, Overfit의 경우 training시에 정확성은 높지만 test에서 오차범위가 크게 예측을 할 수 가 있다.</span><br><br><br><span style="background-color: skyblue">예를 들어 Underfit인 경우 사과를 맞추는 로봇이 있다고 가정했을 때 ‘사과는 동그랗고 빨갛다’ 라고만 학습시키고 테스트를 했을 때 석류나 자두같이 동그랗고 빨간 과일을 보게되어도 사과라고 예측할 것이다. Overfit의 경우는 ‘지름이 10cm이며 동그랗고 빨간색이다’ 라고 학습 시킨 경우에는 자두같이 작지만 빨간 과일에 대해서는 사과라고 예측하지는 않겠지만 10cm가 넘는 사과이거나 초록색 사과인 경우를 사과라고 판단하지 못하는 오류를 범할 수 있다</span></p>
<h2 id="Model-성능-평가하는-2가지-방법"><a href="#Model-성능-평가하는-2가지-방법" class="headerlink" title="Model 성능 평가하는 2가지 방법"></a>Model 성능 평가하는 2가지 방법</h2><h3 id="Hold-out"><a href="#Hold-out" class="headerlink" title="Hold out"></a>Hold out</h3><blockquote>
<p>Train-test-split</p>
</blockquote>
<p><strong>Data leakage</strong> training data에는 있지만 test data에는 없어 overfitting된경우 발생하는 문제</p>
<h3 id="Cross-Validation-교차-검증"><a href="#Cross-Validation-교차-검증" class="headerlink" title="Cross Validation (교차 검증)"></a>Cross Validation (교차 검증)</h3><blockquote>
<p>n등분 나누어 test, train을 n번 수행하여 평균을 내어 성능을 테스트한다. <br><br>보통 10등분으로 함. <br><br>모든 데이터가 최소 한번은 테스트 데이터로 쓰이도록 한다. <br><br>데이터가 적을때 대충의 성능평가를 할때 cross_val_score를 사용한다 <br></p>
</blockquote>
<p>data leakage현상을 방지할 수 있다.<br><br>데이터의 양이 많으면 매우 느리다는 단점이 있다.</p>
<h2 id="Model의-성능이-좌우되는-요소-2가지"><a href="#Model의-성능이-좌우되는-요소-2가지" class="headerlink" title="Model의 성능이 좌우되는 요소 2가지"></a>Model의 성능이 좌우되는 요소 2가지</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 알고리즘</span><br><span class="line">2. 하이퍼 파라미터</span><br></pre></td></tr></table></figure>

<p><strong>복습시간</strong>  21시 10분 ~ 1시 / 2시간 50분</p>
<p><a id = '23th'></a></p>
<h1 id="2019년-6월-10일-월요일-23th"><a href="#2019년-6월-10일-월요일-23th" class="headerlink" title="2019년 6월 10일 월요일 23th"></a>2019년 6월 10일 월요일 23th</h1><h2 id="map-vs-apply"><a href="#map-vs-apply" class="headerlink" title="map vs apply"></a>map vs apply</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. map은 dictionary, 함수 방식 둘다 지원</span><br><span class="line">2. apply는 함수방식만 지원</span><br><span class="line">- apply방식은 args&#x3D;() 옵션으로 재활용 가능한 함수 방식을 사용할 수 있다</span><br></pre></td></tr></table></figure>

<br>

<h2 id="count-vs-size"><a href="#count-vs-size" class="headerlink" title="count vs size"></a>count vs size</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">count는 미싱데이터를 포함하지 않고</span><br><span class="line">size는 포함한다</span><br></pre></td></tr></table></figure>

<br>

<h3 id="count"><a href="#count" class="headerlink" title="count"></a>count</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">b = (<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">a.count(<span class="number">1</span>)</span><br><span class="line">b.count(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">: <span class="number">3</span></span><br><span class="line">  <span class="number">2</span></span><br></pre></td></tr></table></figure>

<h3 id="size"><a href="#size" class="headerlink" title="size"></a>size</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">c = np.arange(<span class="number">10</span>)</span><br><span class="line">c.size</span><br><span class="line"></span><br><span class="line">: <span class="number">10</span></span><br></pre></td></tr></table></figure>

<h2 id="cut-amp-qcut"><a href="#cut-amp-qcut" class="headerlink" title="cut &amp; qcut"></a>cut &amp; qcut</h2><h3 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h3><blockquote>
<p>최저값과 최대값의 간격을 n등분하여 나눔</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">20</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">49</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">30</span>],[<span class="number">10</span>,<span class="number">11</span>,<span class="number">100</span>]])</span><br><span class="line">x=pd.DataFrame(a)</span><br><span class="line">x.rename(&#123;<span class="number">0</span>:<span class="string">'x'</span>,<span class="number">1</span>:<span class="string">'y'</span>,<span class="number">2</span>:<span class="string">'z'</span>&#125;, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">pd.cut(x.z,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line"><span class="number">0</span>    (<span class="number">1.902</span>, <span class="number">51.0</span>]</span><br><span class="line"><span class="number">1</span>    (<span class="number">1.902</span>, <span class="number">51.0</span>]</span><br><span class="line"><span class="number">2</span>    (<span class="number">1.902</span>, <span class="number">51.0</span>]</span><br><span class="line"><span class="number">3</span>    (<span class="number">1.902</span>, <span class="number">51.0</span>]</span><br><span class="line"><span class="number">4</span>    (<span class="number">1.902</span>, <span class="number">51.0</span>]</span><br><span class="line"><span class="number">5</span>    (<span class="number">51.0</span>, <span class="number">100.0</span>]</span><br></pre></td></tr></table></figure>

<h3 id="qcut"><a href="#qcut" class="headerlink" title="qcut"></a>qcut</h3><blockquote>
<p>전체 데이터 갯수에서 n%로 나눔</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">20</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">49</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">30</span>],[<span class="number">10</span>,<span class="number">11</span>,<span class="number">100</span>]])</span><br><span class="line">x=pd.DataFrame(a)</span><br><span class="line">x.rename(&#123;<span class="number">0</span>:<span class="string">'x'</span>,<span class="number">1</span>:<span class="string">'y'</span>,<span class="number">2</span>:<span class="string">'z'</span>&#125;, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">pd.qcut(x.z,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line"><span class="number">0</span>    (<span class="number">1.999</span>, <span class="number">25.0</span>]</span><br><span class="line"><span class="number">1</span>    (<span class="number">1.999</span>, <span class="number">25.0</span>]</span><br><span class="line"><span class="number">2</span>    (<span class="number">1.999</span>, <span class="number">25.0</span>]</span><br><span class="line"><span class="number">3</span>    (<span class="number">25.0</span>, <span class="number">100.0</span>]</span><br><span class="line"><span class="number">4</span>    (<span class="number">25.0</span>, <span class="number">100.0</span>]</span><br><span class="line"><span class="number">5</span>    (<span class="number">25.0</span>, <span class="number">100.0</span>]</span><br></pre></td></tr></table></figure>

<h2 id="Discriminative-vs-Generative"><a href="#Discriminative-vs-Generative" class="headerlink" title="Discriminative  vs Generative"></a>Discriminative  vs Generative</h2><blockquote>
<p>분류하여 예측 하는 모델에는 두 가지 방식이 있다. Discriminative, Generative</p>
</blockquote>
<br>

<h3 id="Discriminative"><a href="#Discriminative" class="headerlink" title="Discriminative"></a>Discriminative</h3><blockquote>
<p>입력 데이터들이 있을때 label data를 구별해내는 방식</p>
</blockquote>
<blockquote>
<p>어떤 입력값(input) x가 주어졌을 때 그 결과값(label) y일 확률을 알아내는 것</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/33630505/59189720-d4f9e880-8bb5-11e9-97e4-69ec7a2a5d09.JPG" alt="discriminative"></p>
<p><span style="background-color: skyblue">대표 알고리즘</span></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. Logistic Regression</span><br><span class="line">2. Conditional Random Field</span><br><span class="line">3. Support Vector Machine</span><br><span class="line">4. Linear Regression</span><br></pre></td></tr></table></figure>

<p><strong>장점</strong> 데이터가 충분할 경우 성능이 좋음</p>
<p><strong>단점</strong> 데이터가 실제 어떤 모습인지 본질을 이해하기 어려움</p>
<br>

<hr>
#### SVM(Support Vector Machine)

<blockquote>
<p>SVM은 수학적으로 증명 가능하고 초평면을 경계로 분류하는 알고리즘 이라고 볼 수 있다 <br><br>선형, 비선형 둘다 성능 좋지만 최적화를 고려 안해 속도가 느리다는 단점이 있다</p>
</blockquote>
<br>

<p><img src="https://user-images.githubusercontent.com/33630505/59195422-e8617f80-8bc6-11e9-8f3e-e05d569ec4d9.JPG" alt="svm"></p>
<hr>

<h3 id="Generative"><a href="#Generative" class="headerlink" title="Generative"></a>Generative</h3><blockquote>
<p>입력값과 결과값이 주어질때, 일정한 분포 규칙속에 존재한다는 가정을 한다.</p>
</blockquote>
<blockquote>
<p>관측 데이터 결합확률 분포를 통해 확률 모델을 만들어낸다. 즉 주어진 데이터를 보고 분포 규칙을 생성해 낸다.</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/33630505/59195390-d384ec00-8bc6-11e9-8dc7-dd27c882753f.JPG" alt="generative"></p>
<br>

<p><img src="https://user-images.githubusercontent.com/33630505/59195454-fadbb900-8bc6-11e9-955e-51f5048ee8ec.JPG" alt="generative2"></p>
<p><span style="background-color: skyblue">대표 알고리즘</span></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Naive Bayes</span><br><span class="line">2. Gaussian discriminant Analysis</span><br><span class="line">3. Gaussian Mixture Model</span><br></pre></td></tr></table></figure>

<p><strong>장점</strong> 데이터 자체의 특성을 파악하기에 좋다, 데이터를 생성해 새로운 결과물을 얻어낼 수 있다.</p>
<p><strong>단점</strong> 데이터가 많은 경우 Discriminative에 비해 성능이 떨어 질수 있다.</p>
<p>Generative &amp; Discriminative: <a href="https://m.blog.naver.com/PostView.nhn?blogId=2feelus&logNo=221078340870&proxyReferer=https%3A%2F%2Fwww.google.com%2F" target="_blank" rel="noopener">naver blog</a><br><br></p>
<p>선형, 비선형 모델 : <a href="https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-3-7-%EC%BB%A4%EB%84%90-%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0/" target="_blank" rel="noopener">blog</a><br></p>
<h2 id="LogisticRegression을-제일처음에-하는-이유"><a href="#LogisticRegression을-제일처음에-하는-이유" class="headerlink" title="LogisticRegression을 제일처음에 하는 이유"></a>LogisticRegression을 제일처음에 하는 이유</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression은 데이터가 선형분류로 성능이 좋은지 안좋은지를 보고</span><br><span class="line">데이터가 선형 데이터인가 비선형 데이터인가 판별하는데</span><br><span class="line">기준이 될 수 있기 때문에 시간 절약을 할 수 있다</span><br><span class="line"></span><br><span class="line">선형분류와 비선형분류 알고리즘 둘다 성능이 비슷한 경우 선형데이터라고 간주하고</span><br><span class="line">선형분류 알고리즘 위주로 학습시키는데 사용하고</span><br><span class="line"></span><br><span class="line">선형분류 알고리즘의 성능이 현저하게 낮은 경우 비선형 데이터라고 간주하고</span><br><span class="line">그때부터는 비선형 알고리즘 위주로 학습시키는데 사용하면 시간을 절약할 수 있다</span><br></pre></td></tr></table></figure>

<br>

<p><strong>복습시간</strong>  18시 30분 ~ 22시 10분 / 총 3시간 40분</p>
<p><a id = '24th'></a></p>
<h1 id="2019년-6월-12일-수요일-24th"><a href="#2019년-6월-12일-수요일-24th" class="headerlink" title="2019년 6월 12일 수요일 24th"></a>2019년 6월 12일 수요일 24th</h1><h2 id="import를-하지-않고-외부-객체의-메소드를-사용-하는-방법"><a href="#import를-하지-않고-외부-객체의-메소드를-사용-하는-방법" class="headerlink" title="import를 하지 않고 외부 객체의 메소드를 사용 하는 방법"></a>import를 하지 않고 외부 객체의 메소드를 사용 하는 방법</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">iris = sns.load_dataset(<span class="string">'iris'</span>)</span><br><span class="line"></span><br><span class="line">$whos</span><br><span class="line">:</span><br><span class="line">Variable   Type         Data/Info</span><br><span class="line">---------------------------------</span><br><span class="line">iris       DataFrame         sepal_length  sepal_&lt;...&gt;n\n[<span class="number">150</span> rows x <span class="number">5</span> columns]</span><br><span class="line">sns        module       &lt;module <span class="string">'seaborn'</span> <span class="keyword">from</span> <span class="string">'C&lt;...&gt;s\\seaborn\\__init__.py'</span>&gt;</span><br><span class="line"></span><br><span class="line">dir(iris)</span><br><span class="line">:</span><br><span class="line">[<span class="string">'T'</span>,</span><br><span class="line"> <span class="string">'_AXIS_ALIASES'</span>,</span><br><span class="line"> <span class="string">'_AXIS_IALIASES'</span>,</span><br><span class="line"> <span class="string">'_AXIS_LEN'</span>,</span><br><span class="line"> ....</span><br><span class="line"> <span class="string">'boxplot'</span>,</span><br><span class="line"> <span class="string">'iloc'</span>,</span><br><span class="line"> <span class="string">'index'</span>,</span><br><span class="line"> <span class="string">'infer_objects'</span>,</span><br><span class="line"> <span class="string">'info'</span>,</span><br><span class="line"> <span class="string">'insert'</span>,</span><br><span class="line"> <span class="string">'interpolate'</span>,</span><br><span class="line"> <span class="string">'isin'</span>,</span><br><span class="line"> .....</span><br></pre></td></tr></table></figure>

<blockquote>
<p>DataFrame 객체는  Pandas 프레임워크에 정의된 클래스이다. 따라서 Pandas를 import하지 않고는 사용할 수 없다.</p>
</blockquote>
<blockquote>
<p>하지만 import seaborn만 했는데 iris 객체가 DataFrame 타입으로 나온다. 어떻게 된것일까?</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!pip install seaborn</span><br><span class="line"></span><br><span class="line">Requirement already satisfied: seaborn in c:\users\samsung\anaconda3\lib\site-packages (0.9.0)</span><br><span class="line">Requirement already satisfied: numpy&gt;=1.9.3 in c:\users\samsung\anaconda3\lib\site-packages (from seaborn) (1.16.2)</span><br><span class="line">Requirement already satisfied: scipy&gt;=0.14.0 in c:\users\samsung\anaconda3\lib\site-packages (from seaborn) (1.2.1)</span><br><span class="line">Requirement already satisfied: pandas&gt;=0.15.2 in c:\users\samsung\anaconda3\lib\site-packages (from seaborn) (0.24.2)</span><br><span class="line">Requirement already satisfied: matplotlib&gt;=1.4.3 in c:\users\samsung\anaconda3\lib\site-packages (from seaborn) (3.0.3)</span><br><span class="line">Requirement already satisfied: pytz&gt;=2011k in c:\users\samsung\anaconda3\lib\site-packages (from pandas&gt;=0.15.2-&gt;seaborn) (2018.9)</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>

<blockquote>
<p>seaborn을 설치하게되면 numpy, scipy, pandas 등 같이 설치하게 된다. 왜냐하면 seaborn을 사용하기 위해서는 모두 필요하기 때문이다.</p>
</blockquote>
<blockquote>
<p>설치가 되었다고 해서 import하지 않고 쓸수 있다는 말은 아니다. seaborn 패키지 자체에서 numpy든 pandas든 import해서 seaborn으로 dataset을 생성하면 DataFrame 형태로 반환하도록 설계되어 있어 DataFrame 객체가 네임스페이스에 들어 있게 되면 DataFrame이 사용할 수 있는 메소드는 전부 사용할 수 있게 되는 것이다.</p>
</blockquote>
<h2 id="상황에-따른-알고리즘-사용법"><a href="#상황에-따른-알고리즘-사용법" class="headerlink" title="상황에 따른 알고리즘 사용법"></a>상황에 따른 알고리즘 사용법</h2><p><img src="https://user-images.githubusercontent.com/33630505/59346577-926b1400-8d4d-11e9-893c-04293ef73f8c.JPG" alt="algorithm"></p>
<h2 id="데이터의-양이-충분한지-판단하는-방법"><a href="#데이터의-양이-충분한지-판단하는-방법" class="headerlink" title="데이터의 양이 충분한지 판단하는 방법"></a>데이터의 양이 충분한지 판단하는 방법</h2><blockquote>
<p>데이터 분석시 info정보만으로 데이터의 양이 충분한지 안한지 가늠이 가지 않을때 Learning curve를 확인하여 데이터 양이 충분한지 판단한다.</p>
</blockquote>
<blockquote>
<p>Learning curve란 학습시킬때마다 정확도가 어떻게 달라지는지 추세를 확인하여 training score와 cv score가 만나는 지점 즉, overfitting되기 전 적당한 trade-off 지점을 확인할 수 있는 데이터 양이라고 한다면 데이터가 충분하다는 말</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn_evaluation <span class="keyword">import</span> plot</span><br><span class="line">!pip install sklearn-evaluation</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">data = pd.DataFrame(iris.data, columns=list(<span class="string">'ABCD'</span>))</span><br><span class="line">target = pd.DataFrame(iris.target, columns=[<span class="string">'target'</span>])</span><br><span class="line">iris2 = pd.concat([data, target], axis=<span class="number">1</span>)</span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">train_size, train_score, test_score = learning_curve(knn, iris2.iloc[:,:<span class="number">-1</span>], iris2.iloc[:,<span class="number">-1</span>], cv = <span class="number">10</span>)</span><br><span class="line">plot.learning_curve(train_score, test_score, train_size)</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59351013-699c4c00-8d58-11e9-8ada-647b976d4949.JPG" alt="learning curve"></p>
<h2 id="Learning-curve-amp-LogisticRegression"><a href="#Learning-curve-amp-LogisticRegression" class="headerlink" title="Learning curve &amp; LogisticRegression"></a>Learning curve &amp; LogisticRegression</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">data = make_classification(<span class="number">1000</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">d = pd.DataFrame(data[<span class="number">0</span>])</span><br><span class="line">ta = pd.DataFrame(data[<span class="number">1</span>])</span><br><span class="line">train_size, train_score, test_score = learning_curve(lr, d, ta, cv=<span class="number">10</span>)</span><br><span class="line">plot.learning_curve(train_score, test_score, train_size)</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59358328-4f1d9f00-8d67-11e9-83ce-43b6da0756ef.JPG" alt="logistic learning curve"></p>
<h2 id="하이퍼-파라미터-찾기-GridSearchCV"><a href="#하이퍼-파라미터-찾기-GridSearchCV" class="headerlink" title="하이퍼 파라미터 찾기 (GridSearchCV)"></a>하이퍼 파라미터 찾기 (GridSearchCV)</h2><blockquote>
<p>GridSearch를 활용하여 for문을 쓰지 않고 하이퍼 파라미터 찾기</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># iris2는 위에서 다룬 예제를 대체한다</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris2.iloc[:,:<span class="number">-1</span>], iris2.iloc[:,<span class="number">-1</span>])</span><br><span class="line">para_grid = &#123;<span class="string">'n_neighbors'</span>: range(<span class="number">2</span>,<span class="number">21</span>), <span class="string">'weights'</span>:[<span class="string">'uniform'</span>, <span class="string">'distance'</span>]&#125;</span><br><span class="line">gri = GridSearchCV(KNeighborsClassifier(), para_grid)</span><br><span class="line">gri.fit(x_train, y_train)  <span class="comment"># cross validation이기 때문에 전체 데이터로 fit 시켜야함</span></span><br><span class="line">gri.best_estimator_</span><br><span class="line">gri.best_params_</span><br><span class="line">gri.param_grid</span><br><span class="line">gri.best_score_</span><br><span class="line">pd.DataFrame(gri.cv_results_).T</span><br><span class="line"></span><br><span class="line">: GridSearchCV(cv=<span class="string">'warn'</span>, error_score=<span class="string">'raise-deprecating'</span>,</span><br><span class="line">       estimator=KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">           metric_params=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, n_neighbors=<span class="number">5</span>, p=<span class="number">2</span>,</span><br><span class="line">           weights=<span class="string">'uniform'</span>),</span><br><span class="line">       fit_params=<span class="literal">None</span>, iid=<span class="string">'warn'</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">       param_grid=&#123;<span class="string">'n_neighbors'</span>: range(<span class="number">2</span>, <span class="number">21</span>), <span class="string">'weights'</span>: [<span class="string">'uniform'</span>, <span class="string">'distance'</span>]&#125;,</span><br><span class="line">       pre_dispatch=<span class="string">'2*n_jobs'</span>, refit=<span class="literal">True</span>, return_train_score=<span class="string">'warn'</span>,</span><br><span class="line">       scoring=<span class="literal">None</span>, verbose=<span class="number">0</span>)</span><br><span class="line">KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">           metric_params=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, n_neighbors=<span class="number">13</span>, p=<span class="number">2</span>,</span><br><span class="line">           weights=<span class="string">'distance'</span>)   </span><br><span class="line">&#123;<span class="string">'n_neighbors'</span>: <span class="number">13</span>, <span class="string">'weights'</span>: <span class="string">'distance'</span>&#125;</span><br><span class="line">&#123;<span class="string">'n_neighbors'</span>: range(<span class="number">2</span>, <span class="number">21</span>), <span class="string">'weights'</span>: [<span class="string">'uniform'</span>, <span class="string">'distance'</span>]&#125;</span><br><span class="line"><span class="number">0.9821428571428571</span></span><br></pre></td></tr></table></figure>


<p><img src="https://user-images.githubusercontent.com/33630505/59363332-f43c7580-8d6f-11e9-8858-226de6ce3354.JPG" alt="gri_results"></p>
<p><strong>LogisticRegression</strong> LogisticRegression알고리즘은 target data가 2개 이상일때만 Learning curve가 가능하다.</p>
<p><strong>Cross-validation &amp; Learning curve</strong> Cross-validation으로 성능 체크할때 n개로 나누어 체크를 하는데 이때 자동으로 데이터를 섞고나서 평가를 하기 때문에 데이터가 정렬 되어 있어도 섞어서 평가를 한다. 그런데 Learning curve로 학습 추세를 확인 할때는 데이터를 순서대로 학습시키기 때문에 최소 클래스 2개가 필요한 LogisticRegression알고리즘을 사용할 때는 shuffle 옵션을 True로 줘야 한다.</p>
<p><strong>복습시간</strong>  19시 ~  22시/ 총 3시간</p>
<p><a id = '25th'></a></p>
<h1 id="2019년-6월-13일-목요일-25th"><a href="#2019년-6월-13일-목요일-25th" class="headerlink" title="2019년 6월 13일 목요일 25th"></a>2019년 6월 13일 목요일 25th</h1><h2 id="Supervised-Learning-Process"><a href="#Supervised-Learning-Process" class="headerlink" title="Supervised Learning Process"></a>Supervised Learning Process</h2><p><img src="https://user-images.githubusercontent.com/33630505/59368687-bba19980-8d79-11e9-91bc-63d9a8d3988e.JPG" alt="supervised learning process"></p>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Raw Data Collection</span> <br></p>
<p style = "border: 1.2px solid black; border-radius: 7px; display: block; padding: 10;">데이터 수집, 적합한 데이터 format으로 불러오기.
        기초 통계분석하기 위해 보통 DataFrame 형태로 불러오거나 변환해준다.</p>

<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Pre-Processing</span> <br>        </p>
<p style = "border: 1.2px solid black; border-radius: 7px; display: block; padding: 10;">Tidy Data인지 확인한다.
        Tidy Data가 아닐 경우 변수는 열로 관측치는 행으로 구성할 수 있도록 melt로 행, 열 변환해준다. </p>

<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Sampling</span> <br></p>
<p style = "border: 1.2px solid black; border-radius: 7px; display: block; padding: 10;">Train-Test-Split 하거나 데이터 양이 많지 않아 대략적인 성능을 알고 싶을 때는 Cross Validation. 보통 Big Data를 다룬다는 가정이 있기 때문에 Train-Test-Split을 한다.</p>

<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Pre-Processing</span> <br></p>
<p style = "border: 1.2px solid black; border-radius: 7px; display: block; padding: 10;">info를 통해 데이터 양이 충분한지, 열 이름에 공백이나 특수문자는 없는지, 데이터 타입이 모두 숫자인지, 불러드릴 수 있는 크기인지, label data를 포함하고 있는지 등을 체크한다.
        이때 데이터 양이 충분한지 여부를 확인하고 싶을때는 Learning Curve를 확인한다.
        데이터 양이 적다고 판단이 되어 데이터 수집을 해야하는데 데이터 수집할 형편이 되지 않는다면 차원 축소를 고려해본다.
        차원 축소는 Scaling, 수작업 등으로 한다.

<pre><code>&lt;/p&gt;</code></pre><p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Learning Algorithm Training</span> <br>        </p>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Hyperparameter Optimization</span> <br></p>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Post-Processing</span> <br></p>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Final Model</span> <br></p>
<h2 id="Pandas-Profiling"><a href="#Pandas-Profiling" class="headerlink" title="Pandas-Profiling"></a>Pandas-Profiling</h2><h3 id="설치"><a href="#설치" class="headerlink" title="설치"></a>설치</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install pandas-profiling</span><br></pre></td></tr></table></figure>

<h3 id="예제"><a href="#예제" class="headerlink" title="예제"></a>예제</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas_profiling <span class="keyword">import</span> ProfileReport</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">data = load_wine()</span><br><span class="line">data1=pd.DataFrame(data.data, columns=data.feature_names)</span><br><span class="line">data2 = pd.DataFrame(data.target, columns=[<span class="string">'target'</span>])</span><br><span class="line">data3 = pd.concat([data1,data2], axis=<span class="number">1</span>)</span><br><span class="line">ProfileReport(data3)</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59434512-a59de280-8e26-11e9-8053-1d2431cea98c.JPG" alt="overview"></p>
<blockquote>
<p>ProfileReport를 사용해서 자기만의 전처리 방식을 자동화 할 수도 있다.</p>
</blockquote>
<h2 id="차원-축소-3가지-방법"><a href="#차원-축소-3가지-방법" class="headerlink" title="차원 축소 3가지 방법"></a>차원 축소 3가지 방법</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Feature Scaling</span><br><span class="line">2. Feature Selection</span><br><span class="line">3. Dimensionality Reduction</span><br></pre></td></tr></table></figure>

<h3 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h3><h4 id="13개-차원에서-5개-차원으로-축소"><a href="#13개-차원에서-5개-차원으로-축소" class="headerlink" title="13개 차원에서 5개 차원으로 축소"></a>13개 차원에서 5개 차원으로 축소</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = load_wine()</span><br><span class="line">wine = pd.DataFrame(data.data, columns=data.feature_names)</span><br><span class="line">target = pd.DataFrame(data.target, columns=[<span class="string">'target'</span>])</span><br><span class="line">wine_data = pd.concat([wine, target], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">pca = PCA(<span class="number">5</span>)</span><br><span class="line">wine_pca = pca.fit_transform(wine_data.iloc[:,:<span class="number">-1</span>])</span><br><span class="line">wine2 = pd.DataFrame(wine_pca)</span><br><span class="line">wine2_data = pd.concat([wine2, wine_data.target], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 13차원</span></span><br><span class="line">cross_val_score(KNeighborsClassifier(), wine_data.iloc[:,:<span class="number">-1</span>], wine_data.iloc[:,<span class="number">-1</span>], cv=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 5차원</span></span><br><span class="line">cross_val_score(KNeighborsClassifier(), wine2_data.iloc[:,:<span class="number">-1</span>], wine2_data.iloc[:,<span class="number">-1</span>], cv=<span class="number">10</span>)</span><br><span class="line">:</span><br><span class="line">array([<span class="number">0.68421053</span>, <span class="number">0.61111111</span>, <span class="number">0.66666667</span>, <span class="number">0.55555556</span>, <span class="number">0.66666667</span>,</span><br><span class="line">       <span class="number">0.55555556</span>, <span class="number">0.77777778</span>, <span class="number">0.66666667</span>, <span class="number">0.82352941</span>, <span class="number">0.75</span>      ])</span><br><span class="line"></span><br><span class="line">array([<span class="number">0.68421053</span>, <span class="number">0.61111111</span>, <span class="number">0.66666667</span>, <span class="number">0.55555556</span>, <span class="number">0.66666667</span>,</span><br><span class="line">       <span class="number">0.55555556</span>, <span class="number">0.77777778</span>, <span class="number">0.66666667</span>, <span class="number">0.82352941</span>, <span class="number">0.75</span>      ])</span><br></pre></td></tr></table></figure>

<blockquote>
<p>차원 축소 전과 축소 후 성능 비교후 성능이 축소 전과 비슷하다면 상관성이 높다는 의미로 차원을 축소해도 괜찮다.</p>
</blockquote>
<blockquote>
<p>데이터의 양이 차원에 비해 작을때 차원 축소로 성능 향상을 하기도 한다.</p>
</blockquote>
<p><span style="background-color:red">밑에 부터는 복습 자세하게 다시하기</span></p>
<h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><blockquote>
<p>pipeline은 …</p>
</blockquote>
<h3 id="Pipeline만드는-두가지-방법"><a href="#Pipeline만드는-두가지-방법" class="headerlink" title="Pipeline만드는 두가지 방법"></a>Pipeline만드는 두가지 방법</h3><p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">Pipeline</span> <br></p>
<p><span style = "border: 1.2px solid rgb(45, 164, 164); background-color: rgb(45, 164, 164); color: white">make_pipeline</span> <br></p>
<h3 id="Pipeline-1"><a href="#Pipeline-1" class="headerlink" title="Pipeline"></a>Pipeline</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> missingno <span class="keyword">as</span> mino</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">data = load_breast_cancer()</span><br><span class="line">X, y = pd.DataFrame(data.data), pd.DataFrame(data.target, columns=[<span class="string">'target'</span>])</span><br><span class="line">cancer = pd.concat([X, y], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">t = cross_val_score(KNeighborsClassifier(),</span><br><span class="line">                    cancer.iloc[:, :<span class="number">-1</span>],</span><br><span class="line">                    cancer.iloc[:, <span class="number">-1</span>],</span><br><span class="line">                    cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(cancer.iloc[:, :<span class="number">-1</span>], cancer.iloc[:, <span class="number">-1</span>])</span><br><span class="line">pipe = Pipeline([(<span class="string">'scaler'</span>, MinMaxScaler()), (<span class="string">'knn'</span>, KNeighborsClassifier())])</span><br><span class="line">pipe.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">: Pipeline(memory=<span class="literal">None</span>,</span><br><span class="line">         steps=[(<span class="string">'scaler'</span>, MinMaxScaler(copy=<span class="literal">True</span>, feature_range=(<span class="number">0</span>, <span class="number">1</span>))),</span><br><span class="line">                (<span class="string">'knn'</span>,</span><br><span class="line">                 KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>,</span><br><span class="line">                                      metric=<span class="string">'minkowski'</span>, metric_params=<span class="literal">None</span>,</span><br><span class="line">                                      n_jobs=<span class="literal">None</span>, n_neighbors=<span class="number">5</span>, p=<span class="number">2</span>,</span><br><span class="line">                                      weights=<span class="string">'uniform'</span>))],</span><br><span class="line">         verbose=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="표준화"><a href="#표준화" class="headerlink" title="표준화"></a>표준화</h2><h2 id="GridSearchCV-Pipeline-하는-방법"><a href="#GridSearchCV-Pipeline-하는-방법" class="headerlink" title="GridSearchCV + Pipeline 하는 방법"></a>GridSearchCV + Pipeline 하는 방법</h2><p><strong>복습시간</strong>  19시 ~ 22시 / 총 3시간  </p>
<p><a id = '26th'></a></p>
<h1 id="2019년-6월-14일-금요일-26th"><a href="#2019년-6월-14일-금요일-26th" class="headerlink" title="2019년 6월 14일 금요일 26th"></a>2019년 6월 14일 금요일 26th</h1><h2 id="Unsupervised-Learnling"><a href="#Unsupervised-Learnling" class="headerlink" title="Unsupervised Learnling"></a>Unsupervised Learnling</h2><h2 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h2><blockquote>
<p>근처 값의 평균을 내어 n개로 묶는 clustering 방법</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line"></span><br><span class="line">km = KMeans(<span class="number">3</span>)  <span class="comment"># 3가지로 묶는다</span></span><br><span class="line">vars(km.fit(iris_data.values))  </span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">&#123;<span class="string">'n_clusters'</span>: <span class="number">3</span>,</span><br><span class="line"> <span class="string">'init'</span>: <span class="string">'k-means++'</span>,</span><br><span class="line"> <span class="string">'max_iter'</span>: <span class="number">300</span>,</span><br><span class="line"> <span class="string">'tol'</span>: <span class="number">0.0001</span>,</span><br><span class="line"> <span class="string">'precompute_distances'</span>: <span class="string">'auto'</span>,</span><br><span class="line"> <span class="string">'n_init'</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">'verbose'</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">'random_state'</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">'copy_x'</span>: <span class="literal">True</span>,</span><br><span class="line"> <span class="string">'n_jobs'</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">'algorithm'</span>: <span class="string">'auto'</span>,</span><br><span class="line"> <span class="string">'cluster_centers_'</span>: array([[<span class="number">6.85</span>      , <span class="number">3.07368421</span>, <span class="number">5.74210526</span>, <span class="number">2.07105263</span>],</span><br><span class="line">        [<span class="number">5.006</span>     , <span class="number">3.428</span>     , <span class="number">1.462</span>     , <span class="number">0.246</span>     ],</span><br><span class="line">        [<span class="number">5.9016129</span> , <span class="number">2.7483871</span> , <span class="number">4.39354839</span>, <span class="number">1.43387097</span>]]),</span><br><span class="line"> <span class="string">'labels_'</span>: array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">        <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">        <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">        <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">        <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>]),</span><br><span class="line"> <span class="string">'inertia_'</span>: <span class="number">78.85144142614601</span>,</span><br><span class="line"> <span class="string">'n_iter_'</span>: <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>

<p>k-means : <a href="https://ratsgo.github.io/machine%20learning/2017/04/19/KC/" target="_blank" rel="noopener">github blog</a> <br><br><br></p>
<h3 id="k-means로-cluster-성능-파악하기"><a href="#k-means로-cluster-성능-파악하기" class="headerlink" title="k-means로 cluster 성능 파악하기"></a>k-means로 cluster 성능 파악하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris.target  <span class="comment"># target data (정답)</span></span><br><span class="line">:</span><br><span class="line">array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">km.labels_   <span class="comment"># cluster로 묶은 답</span></span><br><span class="line">:</span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">np.where(km.labels_==<span class="number">1</span>)  <span class="comment"># 0 ~ 49 / 100% 맞춤</span></span><br><span class="line">:</span><br><span class="line">(array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>,</span><br><span class="line">        <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>,</span><br><span class="line">        <span class="number">34</span>, <span class="number">35</span>, <span class="number">36</span>, <span class="number">37</span>, <span class="number">38</span>, <span class="number">39</span>, <span class="number">40</span>, <span class="number">41</span>, <span class="number">42</span>, <span class="number">43</span>, <span class="number">44</span>, <span class="number">45</span>, <span class="number">46</span>, <span class="number">47</span>, <span class="number">48</span>, <span class="number">49</span>],</span><br><span class="line">       dtype=int64),)</span><br><span class="line">np.where(km.labels_==<span class="number">2</span>)  <span class="comment"># 50 ~ 99 / 101,106,112 ~ 149 / 2개 틀림  </span></span><br><span class="line">:</span><br><span class="line">(array([ <span class="number">50</span>,  <span class="number">51</span>,  <span class="number">53</span>,  <span class="number">54</span>,  <span class="number">55</span>,  <span class="number">56</span>,  <span class="number">57</span>,  <span class="number">58</span>,  <span class="number">59</span>,  <span class="number">60</span>,  <span class="number">61</span>,  <span class="number">62</span>,  <span class="number">63</span>,</span><br><span class="line">         <span class="number">64</span>,  <span class="number">65</span>,  <span class="number">66</span>,  <span class="number">67</span>,  <span class="number">68</span>,  <span class="number">69</span>,  <span class="number">70</span>,  <span class="number">71</span>,  <span class="number">72</span>,  <span class="number">73</span>,  <span class="number">74</span>,  <span class="number">75</span>,  <span class="number">76</span>,</span><br><span class="line">         <span class="number">78</span>,  <span class="number">79</span>,  <span class="number">80</span>,  <span class="number">81</span>,  <span class="number">82</span>,  <span class="number">83</span>,  <span class="number">84</span>,  <span class="number">85</span>,  <span class="number">86</span>,  <span class="number">87</span>,  <span class="number">88</span>,  <span class="number">89</span>,  <span class="number">90</span>,</span><br><span class="line">         <span class="number">91</span>,  <span class="number">92</span>,  <span class="number">93</span>,  <span class="number">94</span>,  <span class="number">95</span>,  <span class="number">96</span>,  <span class="number">97</span>,  <span class="number">98</span>,  <span class="number">99</span>, <span class="number">101</span>, <span class="number">106</span>, <span class="number">113</span>, <span class="number">114</span>,</span><br><span class="line">        <span class="number">119</span>, <span class="number">121</span>, <span class="number">123</span>, <span class="number">126</span>, <span class="number">127</span>, <span class="number">133</span>, <span class="number">138</span>, <span class="number">142</span>, <span class="number">146</span>, <span class="number">149</span>], dtype=int64),)</span><br><span class="line">np.where(km.labels_==<span class="number">0</span>)  <span class="comment"># 100 ~ 149 / 52, 77 / 14개 틀림</span></span><br><span class="line">:</span><br><span class="line">(array([ <span class="number">52</span>,  <span class="number">77</span>, <span class="number">100</span>, <span class="number">102</span>, <span class="number">103</span>, <span class="number">104</span>, <span class="number">105</span>, <span class="number">107</span>, <span class="number">108</span>, <span class="number">109</span>, <span class="number">110</span>, <span class="number">111</span>, <span class="number">112</span>,</span><br><span class="line">        <span class="number">115</span>, <span class="number">116</span>, <span class="number">117</span>, <span class="number">118</span>, <span class="number">120</span>, <span class="number">122</span>, <span class="number">124</span>, <span class="number">125</span>, <span class="number">128</span>, <span class="number">129</span>, <span class="number">130</span>, <span class="number">131</span>, <span class="number">132</span>,</span><br><span class="line">        <span class="number">134</span>, <span class="number">135</span>, <span class="number">136</span>, <span class="number">137</span>, <span class="number">139</span>, <span class="number">140</span>, <span class="number">141</span>, <span class="number">143</span>, <span class="number">144</span>, <span class="number">145</span>, <span class="number">147</span>, <span class="number">148</span>],</span><br><span class="line">       dtype=int64),)</span><br></pre></td></tr></table></figure>

<h2 id="dbscan"><a href="#dbscan" class="headerlink" title="dbscan"></a>dbscan</h2><blockquote>
<p>묶음 갯수 파악하기</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN, dbscan  <span class="comment"># 둘다 같은 기능</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">dbs = DBSCAN()</span><br><span class="line">dbs.fit(iris_data.iloc[:,:<span class="number">-1</span>])</span><br><span class="line">vars(dbs.fit(iris_data.iloc[:,:<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">DBSCAN(algorithm=<span class="string">'auto'</span>, eps=<span class="number">0.5</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'euclidean'</span>,</span><br><span class="line">    metric_params=<span class="literal">None</span>, min_samples=<span class="number">5</span>, n_jobs=<span class="literal">None</span>, p=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">'eps'</span>: <span class="number">0.5</span>,</span><br><span class="line"> <span class="string">'min_samples'</span>: <span class="number">5</span>,</span><br><span class="line"> <span class="string">'metric'</span>: <span class="string">'euclidean'</span>,</span><br><span class="line"> <span class="string">'metric_params'</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">'algorithm'</span>: <span class="string">'auto'</span>,</span><br><span class="line"> <span class="string">'leaf_size'</span>: <span class="number">30</span>,</span><br><span class="line"> <span class="string">'p'</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">'n_jobs'</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">'core_sample_indices_'</span>: array([  <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">2</span>,   <span class="number">3</span>,   <span class="number">4</span>,   <span class="number">5</span>,   <span class="number">6</span>,   <span class="number">7</span>,   <span class="number">8</span>,   <span class="number">9</span>,  <span class="number">10</span>,  <span class="number">11</span>,  <span class="number">12</span>,</span><br><span class="line">         <span class="number">13</span>,  <span class="number">16</span>,  <span class="number">17</span>,  <span class="number">19</span>,  <span class="number">20</span>,  <span class="number">21</span>,  <span class="number">23</span>,  <span class="number">24</span>,  <span class="number">25</span>,  <span class="number">26</span>,  <span class="number">27</span>,  <span class="number">28</span>,  <span class="number">29</span>,</span><br><span class="line">         <span class="number">30</span>,  <span class="number">31</span>,  <span class="number">32</span>,  <span class="number">33</span>,  <span class="number">34</span>,  <span class="number">35</span>,  <span class="number">36</span>,  <span class="number">37</span>,  <span class="number">38</span>,  <span class="number">39</span>,  <span class="number">40</span>,  <span class="number">42</span>,  <span class="number">43</span>,</span><br><span class="line">         <span class="number">44</span>,  <span class="number">45</span>,  <span class="number">46</span>,  <span class="number">47</span>,  <span class="number">48</span>,  <span class="number">49</span>,  <span class="number">50</span>,  <span class="number">51</span>,  <span class="number">52</span>,  <span class="number">53</span>,  <span class="number">54</span>,  <span class="number">55</span>,  <span class="number">56</span>,</span><br><span class="line">         <span class="number">58</span>,  <span class="number">61</span>,  <span class="number">63</span>,  <span class="number">65</span>,  <span class="number">66</span>,  <span class="number">67</span>,  <span class="number">69</span>,  <span class="number">70</span>,  <span class="number">71</span>,  <span class="number">72</span>,  <span class="number">73</span>,  <span class="number">74</span>,  <span class="number">75</span>,</span><br><span class="line">         <span class="number">76</span>,  <span class="number">77</span>,  <span class="number">78</span>,  <span class="number">79</span>,  <span class="number">80</span>,  <span class="number">81</span>,  <span class="number">82</span>,  <span class="number">83</span>,  <span class="number">84</span>,  <span class="number">85</span>,  <span class="number">86</span>,  <span class="number">88</span>,  <span class="number">89</span>,</span><br><span class="line">         <span class="number">90</span>,  <span class="number">91</span>,  <span class="number">92</span>,  <span class="number">94</span>,  <span class="number">95</span>,  <span class="number">96</span>,  <span class="number">97</span>,  <span class="number">99</span>, <span class="number">101</span>, <span class="number">102</span>, <span class="number">103</span>, <span class="number">104</span>, <span class="number">110</span>,</span><br><span class="line">        <span class="number">111</span>, <span class="number">112</span>, <span class="number">115</span>, <span class="number">116</span>, <span class="number">120</span>, <span class="number">121</span>, <span class="number">123</span>, <span class="number">124</span>, <span class="number">125</span>, <span class="number">126</span>, <span class="number">127</span>, <span class="number">128</span>, <span class="number">132</span>,</span><br><span class="line">        <span class="number">133</span>, <span class="number">136</span>, <span class="number">137</span>, <span class="number">138</span>, <span class="number">139</span>, <span class="number">140</span>, <span class="number">142</span>, <span class="number">143</span>, <span class="number">144</span>, <span class="number">145</span>, <span class="number">146</span>, <span class="number">147</span>, <span class="number">149</span>],</span><br><span class="line">       dtype=int64),</span><br><span class="line"> <span class="string">'labels_'</span>: array([ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,</span><br><span class="line">         <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,</span><br><span class="line">         <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>, <span class="number">-1</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">        <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">       dtype=int64),</span><br><span class="line"> <span class="string">'components_'</span>: array([[<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],</span><br><span class="line">        [<span class="number">4.9</span>, <span class="number">3.</span> , <span class="number">1.4</span>, <span class="number">0.2</span>],</span><br><span class="line">        [<span class="number">4.7</span>, <span class="number">3.2</span>, <span class="number">1.3</span>, <span class="number">0.2</span>],</span><br><span class="line">	......</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min_samples는 영역 안의 최소 데이터 갯수</span><br><span class="line">eps는 영역 크기</span><br></pre></td></tr></table></figure>
<br>

<h2 id="Agglomerative-Clustering"><a href="#Agglomerative-Clustering" class="headerlink" title="Agglomerative Clustering"></a>Agglomerative Clustering</h2><h3 id="Dendrograms"><a href="#Dendrograms" class="headerlink" title="Dendrograms"></a>Dendrograms</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram, linkage</span><br><span class="line"></span><br><span class="line">linkage_matrix = linkage(X, <span class="string">'ward'</span>)</span><br><span class="line">figure = plt.figure(figsize=(<span class="number">7.5</span>, <span class="number">5</span>))</span><br><span class="line">dendrogram(</span><br><span class="line">    linkage_matrix, <span class="comment">#</span></span><br><span class="line">    color_threshold=<span class="number">0</span>,</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">'Hierarchical Clustering Dendrogram (Ward)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'sample index'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'distance'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59520588-44990c00-8f05-11e9-99bb-06d03b26ff40.JPG" alt="dendrogram"></p>
<h2 id="mglearn으로-clustering-시각화-해서-보기"><a href="#mglearn으로-clustering-시각화-해서-보기" class="headerlink" title="mglearn으로 clustering 시각화 해서 보기"></a>mglearn으로 clustering 시각화 해서 보기</h2><h3 id="설치-1"><a href="#설치-1" class="headerlink" title="설치"></a>설치</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install mglearn</span><br></pre></td></tr></table></figure>
<h3 id="k-means방식으로-clustering-하는-과정"><a href="#k-means방식으로-clustering-하는-과정" class="headerlink" title="k-means방식으로 clustering 하는 과정"></a>k-means방식으로 clustering 하는 과정</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mglearn</span><br><span class="line">mglearn.plot_kmeans.plot_kmeans_algorithm()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59517495-ab66f700-8efe-11e9-8de2-fb47d3d01680.JPG" alt="kmeans"></p>
<h3 id="k-means-boundaries"><a href="#k-means-boundaries" class="headerlink" title="k-means boundaries"></a>k-means boundaries</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mglearn</span><br><span class="line">mglearn.plot_kmeans.plot_kmeans_boundaries()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59517493-ab66f700-8efe-11e9-87f4-74532ab636a1.JPG" alt="boundaries"></p>
<h3 id="agglomerative"><a href="#agglomerative" class="headerlink" title="agglomerative"></a>agglomerative</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mglearn</span><br><span class="line">mglearn.plot_agglomerative.plot_agglomerative_algorithm()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59517492-aace6080-8efe-11e9-944c-f61807ea32e0.JPG" alt="agglomerative"></p>
<h3 id="dbscan-1"><a href="#dbscan-1" class="headerlink" title="dbscan"></a>dbscan</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mglearn</span><br><span class="line">mglearn.plot_dbscan.plot_dbscan()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59519335-9db37080-8f02-11e9-8caa-822cf5e52152.JPG" alt="dbscan"></p>
<h2 id="dbscan-k-means"><a href="#dbscan-k-means" class="headerlink" title="dbscan + k-means"></a>dbscan + k-means</h2><hr>
<span style="background-color: red">알고리즘 만들기는 다음시간에 계속</span>

<h2 id="알고리즘-만들기"><a href="#알고리즘-만들기" class="headerlink" title="알고리즘 만들기"></a>알고리즘 만들기</h2><h3 id="Duck-typing-방식"><a href="#Duck-typing-방식" class="headerlink" title="Duck typing 방식"></a>Duck typing 방식</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyEstimator</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'a'</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X,y)</span>:</span></span><br><span class="line">        print(<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">my = MyEstimator()</span><br><span class="line">my.fit(data.iloc[:,:<span class="number">-1</span>],data.iloc[:])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.dummy <span class="keyword">import</span> DummyClassifier</span><br><span class="line">dum = DummyClassifier() <span class="comment"># 사람처럼 분류하는 알고리즘</span></span><br></pre></td></tr></table></figure>

<h3 id="BaseEstimator-상속-방식"><a href="#BaseEstimator-상속-방식" class="headerlink" title="BaseEstimator 상속 방식"></a>BaseEstimator 상속 방식</h3><p><strong>Dummy 알고리즘</strong> Dummy 알고리즘과 내가 만든 알고리즘과 비교해서 성능이 좋지 못하다면 자신만의 알고리즘을 만들 필요가 딱히 없음…</p>
<p><strong>복습시간</strong>  19시 45분 ~ 24시 / 총 4시간 15분  </p>
<p><a id = '27th'></a></p>
<h1 id="2019년-6월-17일-월요일-27th"><a href="#2019년-6월-17일-월요일-27th" class="headerlink" title="2019년 6월 17일 월요일 27th"></a>2019년 6월 17일 월요일 27th</h1><h2 id="영화-추천-모델-만들기"><a href="#영화-추천-모델-만들기" class="headerlink" title="영화 추천 모델 만들기"></a>영화 추천 모델 만들기</h2><h3 id="Collaborative-filtering"><a href="#Collaborative-filtering" class="headerlink" title="Collaborative filtering"></a>Collaborative filtering</h3><blockquote>
<p>나와 비슷한 사람을 찾아 내가본 영화를 제외한 비슷한 사람이 본 영화 추천</p>
</blockquote>
<h3 id="필요한-데이터-불러오기"><a href="#필요한-데이터-불러오기" class="headerlink" title="필요한 데이터 불러오기"></a>필요한 데이터 불러오기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'u.data'</span>, delimiter=<span class="string">'\t'</span>, header=<span class="literal">None</span>, engine=<span class="string">'python'</span>, usecols=range(<span class="number">3</span>),names=[<span class="string">'user_id'</span>,<span class="string">'movie_id'</span>,<span class="string">'ratings'</span>])</span><br><span class="line">items=pd.read_csv(<span class="string">'u.item'</span>, delimiter=<span class="string">'|'</span>, header=<span class="literal">None</span>, engine=<span class="string">'python'</span>, usecols=range(<span class="number">3</span>), names=[<span class="string">'movie_id'</span>,<span class="string">'title'</span>,<span class="string">'year'</span>])</span><br><span class="line"></span><br><span class="line">data.head(<span class="number">4</span>)</span><br><span class="line">:</span><br><span class="line">user_id	movie_id	ratings</span><br><span class="line"><span class="number">0</span>	<span class="number">196</span>	<span class="number">242</span>	<span class="number">3</span></span><br><span class="line"><span class="number">1</span>	<span class="number">186</span>	<span class="number">302</span>	<span class="number">3</span></span><br><span class="line"><span class="number">2</span>	<span class="number">22</span>	<span class="number">377</span>	<span class="number">1</span></span><br><span class="line"><span class="number">3</span>	<span class="number">244</span>	<span class="number">51</span>	<span class="number">2</span></span><br><span class="line"></span><br><span class="line">items.head(<span class="number">4</span>)</span><br><span class="line">:</span><br><span class="line">	movie_id	title	year</span><br><span class="line"><span class="number">0</span>	<span class="number">1</span>	Toy Story (<span class="number">1995</span>)	<span class="number">01</span>-Jan<span class="number">-1995</span></span><br><span class="line"><span class="number">1</span>	<span class="number">2</span>	GoldenEye (<span class="number">1995</span>)	<span class="number">01</span>-Jan<span class="number">-1995</span></span><br><span class="line"><span class="number">2</span>	<span class="number">3</span>	Four Rooms (<span class="number">1995</span>)	<span class="number">01</span>-Jan<span class="number">-1995</span></span><br><span class="line"><span class="number">3</span>	<span class="number">4</span>	Get Shorty (<span class="number">1995</span>)	<span class="number">01</span>-Jan<span class="number">-1995</span></span><br></pre></td></tr></table></figure>

<h3 id="DESCR-README-등-도메인-정보-확인하기"><a href="#DESCR-README-등-도메인-정보-확인하기" class="headerlink" title="DESCR, README 등 도메인 정보 확인하기"></a>DESCR, README 등 도메인 정보 확인하기</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.</span><br><span class="line">              Each user has rated at least 20 movies.  Users and items are</span><br><span class="line">              numbered consecutively from 1.  The data is randomly</span><br><span class="line">              ordered. This is a tab separated list of</span><br><span class="line">	         user id | item id | rating | timestamp.</span><br><span class="line">              The time stamps are unix seconds since 1&#x2F;1&#x2F;1970 UTC</span><br><span class="line"></span><br><span class="line">u.item     -- Information about the items (movies); this is a tab separated</span><br><span class="line">              list of</span><br><span class="line">              movie id | movie title | release date | video release date |</span><br><span class="line">              IMDb URL | unknown | Action | Adventure | Animation |</span><br><span class="line">              Children&#39;s | Comedy | Crime | Documentary | Drama | Fantasy |</span><br><span class="line">              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |</span><br><span class="line">              Thriller | War | Western |</span><br><span class="line">              The last 19 fields are the genres, a 1 indicates the movie</span><br><span class="line">              is of that genre, a 0 indicates it is not; movies can be in</span><br><span class="line">              several genres at once.</span><br><span class="line">              The movie ids are the ones used in the u.data data set.</span><br></pre></td></tr></table></figure>

<h3 id="불러온-정보-필요한-형태로-변형하기"><a href="#불러온-정보-필요한-형태로-변형하기" class="headerlink" title="불러온 정보 필요한 형태로 변형하기"></a>불러온 정보 필요한 형태로 변형하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 유저 아이디 + 영화 아이디 + 평점 + 영화 이름 + 개봉년도 DataFrame 만들기</span></span><br><span class="line">user_movie_rate=pd.merge(data,items)</span><br><span class="line"></span><br><span class="line"><span class="comment"># user index, item columns로 만들기</span></span><br><span class="line">user_item = data.set_index([<span class="string">'user_id'</span>,<span class="string">'movie_id'</span>]).unstack().fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>


<h3 id="회원간의-상관성-보기-어떤-연관성-전략을-세울지-고민"><a href="#회원간의-상관성-보기-어떤-연관성-전략을-세울지-고민" class="headerlink" title="회원간의 상관성 보기 (어떤 연관성 전략을 세울지 고민)"></a>회원간의 상관성 보기 (어떤 연관성 전략을 세울지 고민)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># user_item에서 user가 index이기 때문에 corr하기 위해 Transform 해야함</span></span><br><span class="line">user_item_corr = user_item.T.corr()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59600997-c4a9b680-913d-11e9-983e-e5482a173c99.JPG" alt="user_corr"></p>
<h3 id="연관성이-높은-3명-뽑기-세부-전략-세우기"><a href="#연관성이-높은-3명-뽑기-세부-전략-세우기" class="headerlink" title="연관성이 높은 3명 뽑기 (세부 전략 세우기)"></a>연관성이 높은 3명 뽑기 (세부 전략 세우기)</h3><blockquote>
<p>회원 번호 2를 나라고 가정</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">user_item_corr.loc[<span class="number">2</span>].sort_values(ascending=<span class="literal">False</span>)[:<span class="number">4</span>]</span><br><span class="line">:</span><br><span class="line">user_id</span><br><span class="line"><span class="number">2</span>      <span class="number">1.000000</span></span><br><span class="line"><span class="number">701</span>    <span class="number">0.570307</span></span><br><span class="line"><span class="number">931</span>    <span class="number">0.495166</span></span><br><span class="line"><span class="number">460</span>    <span class="number">0.485913</span></span><br><span class="line">Name: <span class="number">2</span>, dtype: float64</span><br></pre></td></tr></table></figure>

<h3 id="나와-비슷한-사람-영화-목록-나의-영화-목록"><a href="#나와-비슷한-사람-영화-목록-나의-영화-목록" class="headerlink" title="나와 비슷한 사람 영화 목록 - 나의 영화 목록"></a>나와 비슷한 사람 영화 목록 - 나의 영화 목록</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 나의 영화 목록</span></span><br><span class="line">my_movie_list = user_movie_rate[user_movie_rate.user_id==<span class="number">2</span>]</span><br><span class="line">my_movie_list = my_movie_list.movie_id</span><br><span class="line">my_movie_list=set(my_movie_list)</span><br><span class="line">my_movie_list.__len__()</span><br><span class="line">:</span><br><span class="line"><span class="number">62</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 나와 비슷한 사람 영화 목록</span></span><br><span class="line">other = user_movie_rate[user_movie_rate.user_id.isin([<span class="number">701</span>]).movie_id.value</span><br><span class="line">other_movie_list = set(other)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 나와 비슷한 사람 영화 목록 - 나의 영화 목록</span></span><br><span class="line">reco_movie_to_me = other_movie_list - my_movie_list</span><br></pre></td></tr></table></figure>

<h3 id="최종-추천-영화-목록-출력하기"><a href="#최종-추천-영화-목록-출력하기" class="headerlink" title="최종 추천 영화 목록 출력하기"></a>최종 추천 영화 목록 출력하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">reco_movie_to_me=user_movie_rate[user_movie_rate.movie_id.isin(reco_movie_to_me)].sort_values(<span class="string">'ratings'</span>, ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">final_reco_movie_to_me = set(reco_movie_to_me.movie_id.values)</span><br><span class="line">final_my_reco_movie</span><br><span class="line">:</span><br><span class="line">&#123;<span class="number">124</span>, <span class="number">326</span>, <span class="number">328</span>, <span class="number">333</span>, <span class="number">344</span>, <span class="number">689</span>, <span class="number">690</span>, <span class="number">750</span>, <span class="number">751</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 최종 추천 영화 목록</span></span><br><span class="line">list(map(<span class="keyword">lambda</span> x:set(user_movie_rate.title[user_movie_rate.movie_id==x].values),final_my_reco_movie))</span><br><span class="line">:</span><br><span class="line">[&#123;<span class="string">'G.I. Jane (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Conspiracy Theory (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Game, The (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Amistad (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Tomorrow Never Dies (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Jackal, The (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Seven Years in Tibet (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Apostle, The (1997)'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'Lone Star (1996)'</span>&#125;]</span><br></pre></td></tr></table></figure>

<h2 id="Pandas-format-대표값-설정-없이-그대로-변형하는-4가지-방법"><a href="#Pandas-format-대표값-설정-없이-그대로-변형하는-4가지-방법" class="headerlink" title="Pandas format 대표값 설정 없이 그대로 변형하는 4가지 방법"></a>Pandas format 대표값 설정 없이 그대로 변형하는 4가지 방법</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. stack</span><br><span class="line">2. unstack</span><br><span class="line">3. melt</span><br><span class="line">4. pivot</span><br></pre></td></tr></table></figure>

<h3 id="pivot"><a href="#pivot" class="headerlink" title="pivot"></a>pivot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'u.data'</span>, delimiter=<span class="string">'\t'</span>, header=<span class="literal">None</span>, engine=<span class="string">'python'</span>)</span><br><span class="line">data.rename(&#123;<span class="number">0</span>:<span class="string">'user_id'</span>,<span class="number">1</span>:<span class="string">'movie_id'</span>,<span class="number">2</span>:<span class="string">'ratings'</span>&#125;, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">data=data.pivot(<span class="string">'user_id'</span>,<span class="string">'movie_id'</span>,<span class="string">'ratings'</span>)</span><br><span class="line">data.fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59602677-4a2f6580-9142-11e9-93a6-c1cf399baa65.JPG" alt="pivot"></p>
<h2 id="Surprise"><a href="#Surprise" class="headerlink" title="Surprise"></a>Surprise</h2><h3 id="설치-2"><a href="#설치-2" class="headerlink" title="설치"></a>설치</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install surprise</span><br></pre></td></tr></table></figure>

<h3 id="Surprise를-활용하여-예상-별점-예측하기"><a href="#Surprise를-활용하여-예상-별점-예측하기" class="headerlink" title="Surprise를 활용하여 예상 별점 예측하기"></a>Surprise를 활용하여 예상 별점 예측하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> surprise <span class="keyword">import</span> Dataset, Reader, SVD, KNNBasic</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'u.data'</span>, delimiter=<span class="string">'\t'</span>, header=<span class="literal">None</span>, engine=<span class="string">'python'</span>, usecols=range(<span class="number">3</span>),names=[<span class="string">'user_id'</span>,<span class="string">'movie_id'</span>,<span class="string">'ratings'</span>])  </span><br><span class="line"></span><br><span class="line">sur_data = Dataset.load_from_df(data, Reader(rating_scale=(<span class="number">1</span>,<span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">kb = KNNBasic()</span><br><span class="line">svd = SVD()</span><br><span class="line"></span><br><span class="line">kb.fit(sur_data.build_full_trainset())</span><br><span class="line">svd.fit(sur_data.build_full_trainset())</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;124, 326, 328, 333, 344, 689, 690, 750, 751&#125; 위 예제에서 회원아이디 2인 사람의 영화 추천목록</span></span><br><span class="line"></span><br><span class="line">svd.predict(<span class="number">2</span>,<span class="number">344</span>)</span><br><span class="line">:</span><br><span class="line">Prediction(uid=<span class="number">2</span>, iid=<span class="number">344</span>, r_ui=<span class="literal">None</span>, est=<span class="number">3.7619267139014876</span>, details=&#123;<span class="string">'was_impossible'</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">svd.predict(<span class="number">2</span>,<span class="number">124</span>)</span><br><span class="line">:</span><br><span class="line">Prediction(uid=<span class="number">2</span>, iid=<span class="number">124</span>, r_ui=<span class="literal">None</span>, est=<span class="number">4.160187263892665</span>, details=&#123;<span class="string">'was_impossible'</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">kb.predict(<span class="number">2</span>,<span class="number">124</span>)</span><br><span class="line">:</span><br><span class="line">Prediction(uid=<span class="number">2</span>, iid=<span class="number">124</span>, r_ui=<span class="literal">None</span>, est=<span class="number">4.065428928759065</span>, details=&#123;<span class="string">'actual_k'</span>: <span class="number">40</span>, <span class="string">'was_impossible'</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">kb.predict(<span class="number">2</span>,<span class="number">344</span>)</span><br><span class="line">:</span><br><span class="line">Prediction(uid=<span class="number">2</span>, iid=<span class="number">344</span>, r_ui=<span class="literal">None</span>, est=<span class="number">3.696881271344415</span>, details=&#123;<span class="string">'actual_k'</span>: <span class="number">40</span>, <span class="string">'was_impossible'</span>: <span class="literal">False</span>&#125;)</span><br></pre></td></tr></table></figure>

<h2 id="Scikit으로-예상-별점-예측하기"><a href="#Scikit으로-예상-별점-예측하기" class="headerlink" title="Scikit으로 예상 별점 예측하기"></a>Scikit으로 예상 별점 예측하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knn = KNeighborsRegressor(<span class="number">3</span>)</span><br><span class="line">knn.fit(data.iloc[:,:<span class="number">-1</span>],data.iloc[:,<span class="number">-1</span>])</span><br><span class="line">:</span><br><span class="line">KNeighborsRegressor(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">          metric_params=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, n_neighbors=<span class="number">3</span>, p=<span class="number">2</span>,</span><br><span class="line">          weights=<span class="string">'uniform'</span>)</span><br><span class="line"></span><br><span class="line">knn.predict([[<span class="number">2</span>,<span class="number">344</span>]])</span><br><span class="line">:</span><br><span class="line">array([<span class="number">3.33333333</span>])</span><br><span class="line"></span><br><span class="line">knn.predict([[<span class="number">2</span>,<span class="number">124</span>]])</span><br><span class="line">:</span><br><span class="line">array([<span class="number">4.</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################</span></span><br><span class="line">knn = KNeighborsRegressor(<span class="number">40</span>)</span><br><span class="line">knn.fit(data.iloc[:,:<span class="number">-1</span>],data.iloc[:,<span class="number">-1</span>])</span><br><span class="line">:</span><br><span class="line">KNeighborsRegressor(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">          metric_params=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, n_neighbors=<span class="number">40</span>, p=<span class="number">2</span>,</span><br><span class="line">          weights=<span class="string">'uniform'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">knn.predict([[<span class="number">2</span>,<span class="number">344</span>]])</span><br><span class="line">:</span><br><span class="line">array([<span class="number">3.075</span>])</span><br><span class="line"></span><br><span class="line">knn.predict([[<span class="number">2</span>,<span class="number">124</span>]])</span><br><span class="line">:</span><br><span class="line">array([<span class="number">3.9</span>])</span><br></pre></td></tr></table></figure>

<h2 id="plot-knn-regression-mglearn"><a href="#plot-knn-regression-mglearn" class="headerlink" title="plot_knn_regression (mglearn)"></a>plot_knn_regression (mglearn)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mglearn</span><br><span class="line"></span><br><span class="line">mglearn.plot_knn_regression.plot_knn_regression()</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59603791-49e49980-9145-11e9-9970-0ea5d8318d34.JPG" alt="knn_regression"></p>
<h2 id="recommendation-pdf-내용-추가"><a href="#recommendation-pdf-내용-추가" class="headerlink" title="recommendation.pdf 내용 추가"></a>recommendation.pdf 내용 추가</h2><p><strong>복습시간</strong>  19시 10분 ~ 21시 17분 / 총 2시간 7분</p>
<p><a id = '28th'></a></p>
<h1 id="2019년-6월-18일-화요일-28th"><a href="#2019년-6월-18일-화요일-28th" class="headerlink" title="2019년 6월 18일 화요일 28th"></a>2019년 6월 18일 화요일 28th</h1><h2 id="Surprise-vs-Scikit"><a href="#Surprise-vs-Scikit" class="headerlink" title="Surprise vs Scikit"></a>Surprise vs Scikit</h2><h3 id="차이점-2가지"><a href="#차이점-2가지" class="headerlink" title="차이점 2가지"></a>차이점 2가지</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. Train_test_split</span><br><span class="line">2. 평가척도</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Scikit에서는 Train_Test_Split으로 데이터를 나누었지만 Surprise에서는 Fold로 랜덤하게 쪼개준다.</span><br><span class="line">그리고 Scikit에서 평가척도는 score하나 뿐이었지만 Surprise에서는 평가척도로 여러가지가 있다.</span><br><span class="line">예를 들어 rmse(root mean square error) &#x3D;&gt; 평균 제곱근 편차</span><br><span class="line"></span><br><span class="line">Fold &#x3D;&gt; train,test default로 5쌍으로 쪼개어진 generator를 반환한다.</span><br></pre></td></tr></table></figure>


<h3 id="Surprise-예제"><a href="#Surprise-예제" class="headerlink" title="Surprise 예제"></a>Surprise 예제</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> surprise <span class="keyword">import</span> SVD, KNNBasic, Dataset, Reader, dump</span><br><span class="line"><span class="keyword">from</span> surprise.accuracy <span class="keyword">import</span> rmse</span><br><span class="line"></span><br><span class="line">data = Dataset.load_builtin(<span class="string">'ml-100k'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> trainset, testset <span class="keyword">in</span> data.folds():</span><br><span class="line">    algo_knn.fit(trainset)</span><br><span class="line">    predictions_knn = algo_knn.test(testset)</span><br><span class="line">    rmse(predictions_knn)</span><br><span class="line">:</span><br><span class="line">Computing the msd similarity matrix...</span><br><span class="line">Done computing similarity matrix.</span><br><span class="line">RMSE: <span class="number">0.9753</span>                       </span><br><span class="line">Computing the msd similarity matrix...</span><br><span class="line">Done computing similarity matrix.</span><br><span class="line">RMSE: <span class="number">0.9685</span></span><br><span class="line">Computing the msd similarity matrix...</span><br><span class="line">Done computing similarity matrix.</span><br><span class="line">RMSE: <span class="number">0.9870</span></span><br><span class="line">Computing the msd similarity matrix...</span><br><span class="line">Done computing similarity matrix.</span><br><span class="line">RMSE: <span class="number">0.9858</span></span><br><span class="line">Computing the msd similarity matrix...</span><br><span class="line">Done computing similarity matrix.</span><br><span class="line">RMSE: <span class="number">0.9739</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 평균 제곱근 편차가 0.9739면 어떻다는 거니... 생각해보자..</span></span><br></pre></td></tr></table></figure>


<h2 id="os-vs-sys"><a href="#os-vs-sys" class="headerlink" title="os vs sys"></a>os vs sys</h2><blockquote>
<p>os는 파일관련 처리할 때 사용하고 운영체제 내 폴더파일을 다룰때도 사용한다. <br><br>참고로 os는 위험한애임.. <br><br>sys는 파이썬 관점에서 경로를 확인할때 등에 사용되는 모듈 이다. <br><br>자세한건 더 공부하면서 추가해보자.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.path.expanduser</span><br><span class="line">: &lt;module <span class="string">'ntpath'</span> <span class="keyword">from</span> <span class="string">'C:\\Users\\SAMSUNG\\Anaconda3\\lib\\ntpath.py'</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">sys.path</span><br><span class="line">: [<span class="string">'C:\\Users\\SAMSUNG\\Anaconda3\\lib\\site-packages\\win32\\lib'</span>,</span><br><span class="line"> <span class="string">'C:\\Users\\SAMSUNG\\Anaconda3\\lib\\site-packages\\Pythonwin'</span>,</span><br><span class="line"> <span class="string">'C:\\Users\\SAMSUNG\\Anaconda3\\lib\\site-packages\\IPython\\extensions'</span>,</span><br><span class="line"> <span class="string">'C:\\Users\\SAMSUNG\\.ipython'</span>]</span><br></pre></td></tr></table></figure>


<h2 id="Validation-curve"><a href="#Validation-curve" class="headerlink" title="Validation_curve"></a>Validation_curve</h2><blockquote>
<p>GridSearchCV로 하이퍼 파라미터를 찾을때 같이 사용함으로써 적절한 하이퍼 파라미터를 찾기 위해 참고하면 좋다.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> validation_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn_evaluation <span class="keyword">import</span> plot</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">train_scores, test_scores=validation_curve(knn, iris.iloc[:,:<span class="number">-1</span>], iris.iloc[:,<span class="number">-1</span>], <span class="string">'n_neighbors'</span>, [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>], cv=<span class="number">10</span>)</span><br><span class="line">plot.validation_curve(train_scores, test_scores, [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>], <span class="string">'n_neighbors'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59681973-2a667300-9210-11e9-8e1e-384e6233675d.JPG" alt="validation_curve"></p>
<h2 id="Statsmodel로-regression분석하기"><a href="#Statsmodel로-regression분석하기" class="headerlink" title="Statsmodel로 regression분석하기"></a>Statsmodel로 regression분석하기</h2><blockquote>
<p>Linear regression 분석은 머신러닝에서 해설분야를 담당하고 예측하는데 쓰지는 않는다.</p>
</blockquote>
<h3 id="R방식"><a href="#R방식" class="headerlink" title="R방식"></a>R방식</h3><h4 id="설치-3"><a href="#설치-3" class="headerlink" title="설치"></a>설치</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install statsmodels</span><br></pre></td></tr></table></figure>

<h4 id="예제-1"><a href="#예제-1" class="headerlink" title="예제"></a>예제</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"></span><br><span class="line">data = sm.datasets.get_rdataset(<span class="string">"Guerry"</span>, <span class="string">"HistData"</span>).data</span><br><span class="line"></span><br><span class="line">results = smf.ols(<span class="string">'Lottery ~ Literacy + np.log(Pop1831)'</span>,data=data).fit()</span><br><span class="line">results2 = smf.ols(<span class="string">'Lottery ~ Literacy + Instruction'</span>,data=data).fit()</span><br><span class="line"></span><br><span class="line">results.summary()</span><br><span class="line">results2.summary()</span><br></pre></td></tr></table></figure>

<h4 id="results-summary"><a href="#results-summary" class="headerlink" title="results summary"></a>results summary</h4><p><img src="https://user-images.githubusercontent.com/33630505/59684068-4704aa00-9214-11e9-8bd1-4d6417b831f0.JPG" alt="summary"></p>
<h4 id="results2-summary"><a href="#results2-summary" class="headerlink" title="results2 summary"></a>results2 summary</h4><p><img src="https://user-images.githubusercontent.com/33630505/59684100-5552c600-9214-11e9-97e9-9b89f399f6c2.JPG" alt="summary2"></p>
<h3 id="Python-방식"><a href="#Python-방식" class="headerlink" title="Python 방식"></a>Python 방식</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">nobs = <span class="number">100</span></span><br><span class="line">X = np.random.random((nobs, <span class="number">2</span>))</span><br><span class="line">X = sm.add_constant(X)</span><br><span class="line">beta = [<span class="number">1</span>, <span class="number">.1</span>, <span class="number">.5</span>]</span><br><span class="line">e = np.random.random(nobs)</span><br><span class="line">Iy = np.dot(X, beta) + e</span><br><span class="line"></span><br><span class="line">results = sm.OLS(Iy, X).fit()</span><br><span class="line"></span><br><span class="line">print(results.summary())</span><br></pre></td></tr></table></figure>

<p><img src="https://user-images.githubusercontent.com/33630505/59684963-102f9380-9216-11e9-8603-4d2679cf351c.JPG" alt="python_summary"></p>
<p><strong>복습시간</strong>    19시 ~ 22시  / 총 3시간</p>
<p><a id = '29th'></a></p>
<h1 id="2019년-6월-19일-수요일-29th"><a href="#2019년-6월-19일-수요일-29th" class="headerlink" title="2019년 6월 19일 수요일 29th"></a>2019년 6월 19일 수요일 29th</h1><h2 id="버전관리-2가지-방법"><a href="#버전관리-2가지-방법" class="headerlink" title="버전관리 2가지 방법"></a>버전관리 2가지 방법</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. version-information</span><br><span class="line">2. watermark</span><br></pre></td></tr></table></figure>

<h3 id="version-information"><a href="#version-information" class="headerlink" title="version-information"></a>version-information</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 설치 방법</span></span><br><span class="line">!pip install version-information</span><br><span class="line"></span><br><span class="line">%load_ext version_information   <span class="comment"># import 처럼 version_information을 쓰겠다고 명시해주는 구문</span></span><br><span class="line"></span><br><span class="line">%version_information numpy, pandas, seaborn, scikit-learn, statsmodels <span class="comment"># numpy, pandas, seaborn, 등의 버전 명시</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>watermark 방식보다 이쁘게 나온다</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/33630505/59765932-1be48e00-92da-11e9-92f5-29c8becce363.JPG" alt="version_information"></p>
<h3 id="watermark"><a href="#watermark" class="headerlink" title="watermark"></a>watermark</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">%load_ext watermark</span><br><span class="line"></span><br><span class="line">%watermark -a 지혁 -d -p numpy,pandas,seaborn</span><br></pre></td></tr></table></figure>

<blockquote>
<p>version_information은 한글이 깨지지만 watermark는 한글도 지원한다</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/33630505/59765934-1be48e00-92da-11e9-9e6f-08ea3a07d2a7.JPG" alt="watermark"></p>
<h2 id="Feature-selection"><a href="#Feature-selection" class="headerlink" title="Feature-selection"></a>Feature-selection</h2><blockquote>
<p>pre-processing의 일종으로 column을 줄여야겠다는 판단이 들었을때 하는 전처리. <br><br>성능을 높이기 위한 전처리로, 연산 속도를 향상 시키는 방법으로 사용한다. <br><br>이때 정확도 성능을 낮추지 않는 선에서 feature-selection을 진행한다.</p>
</blockquote>
<h3 id="3가지-방식"><a href="#3가지-방식" class="headerlink" title="3가지 방식"></a>3가지 방식</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Filter</span><br><span class="line">2. Embeded</span><br><span class="line">3. Wrapper</span><br></pre></td></tr></table></figure>

<h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><blockquote>
<p>통계값을 보고 경험적으로 도메인 지식을 통해 column을 걸러낸다.</p>
</blockquote>
<h4 id="예시"><a href="#예시" class="headerlink" title="예시"></a>예시</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러와서 DataFrame 형태로 만들기</span></span><br><span class="line">data = load_boston()</span><br><span class="line">boston = pd.DataFrame(data.data, columns=data.feature_names)</span><br><span class="line">target = pd.DataFrame(data.target, columns=[<span class="string">'target'</span>])</span><br><span class="line">boston_target = pd.concat([boston, target], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 기초 통계분석 생략</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pairplot으로 clustering 경향 살피거나 도메인 지식 활용하여 영향력이 가장 없는 column 걸러내기</span></span><br><span class="line"></span><br><span class="line">boston_target_raw=boston_target.copy() <span class="comment"># 원본 데이터 copy해두기</span></span><br><span class="line">boston_target.drop(columns=[<span class="string">'AGE'</span>])  <span class="comment"># 가구당 나이는 집값에 영향이 크지 않다고 판단하여 걸러 내본다.</span></span><br><span class="line">cross_val_score(LinearRegression(), boston_target.iloc[:,:<span class="number">-1</span>], bost_target2.target, cv=<span class="number">10</span>).mean()</span><br><span class="line"></span><br><span class="line">: <span class="number">0.20252899006055775</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 원본 데이터의 정확도</span></span><br><span class="line">cross_val_score(LinearRegression(), boston_target_raw.iloc[:,:<span class="number">-1</span>], bost_target_raw.target, cv=<span class="number">10</span>).mean()</span><br><span class="line"></span><br><span class="line">: <span class="number">0.20252899006055775</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>AGE column을 걸러냈을 때와 걸러내기 전의 정확도가 같기 때문에 age는 영향력이 없는 column! <br><br>따라서 빼도 되는 feature!</p>
</blockquote>
<h3 id="wrapper"><a href="#wrapper" class="headerlink" title="wrapper"></a>wrapper</h3><blockquote>
<p>통계값과 머신러닝 기법을 동시에 사용하여 기준을 두고 ranking을 구해 n개 column 뽑는 방법.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br><span class="line">rfe = RFE(model, <span class="number">7</span>)</span><br><span class="line">X_rfe = rfe.fit_transform(boston_target_raw.iloc[:,:<span class="number">-1</span>], boston_target_raw.target)  <span class="comment"># filter 예시에 있는 boston data 사용</span></span><br><span class="line">X_rfe</span><br><span class="line">:</span><br><span class="line"></span><br><span class="line">array([[ <span class="number">0.</span>   ,  <span class="number">0.538</span>,  <span class="number">6.575</span>, ...,  <span class="number">1.</span>   , <span class="number">15.3</span>  ,  <span class="number">4.98</span> ],</span><br><span class="line">       [ <span class="number">0.</span>   ,  <span class="number">0.469</span>,  <span class="number">6.421</span>, ...,  <span class="number">2.</span>   , <span class="number">17.8</span>  ,  <span class="number">9.14</span> ],</span><br><span class="line">       [ <span class="number">0.</span>   ,  <span class="number">0.469</span>,  <span class="number">7.185</span>, ...,  <span class="number">2.</span>   , <span class="number">17.8</span>  ,  <span class="number">4.03</span> ],</span><br><span class="line">       ...,</span><br><span class="line">       [ <span class="number">0.</span>   ,  <span class="number">0.573</span>,  <span class="number">6.976</span>, ...,  <span class="number">1.</span>   , <span class="number">21.</span>   ,  <span class="number">5.64</span> ],</span><br><span class="line">       [ <span class="number">0.</span>   ,  <span class="number">0.573</span>,  <span class="number">6.794</span>, ...,  <span class="number">1.</span>   , <span class="number">21.</span>   ,  <span class="number">6.48</span> ],</span><br><span class="line">       [ <span class="number">0.</span>   ,  <span class="number">0.573</span>,  <span class="number">6.03</span> , ...,  <span class="number">1.</span>   , <span class="number">21.</span>   ,  <span class="number">7.88</span> ]])</span><br><span class="line"></span><br><span class="line">model.fit(X_rfe, boston_target_raw.target)</span><br><span class="line">:</span><br><span class="line">LinearRegression(copy_X=<span class="literal">True</span>, fit_intercept=<span class="literal">True</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">         normalize=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">vars(rfe)</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">&#123;<span class="string">'estimator'</span>: LinearRegression(copy_X=<span class="literal">True</span>, fit_intercept=<span class="literal">True</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">          normalize=<span class="literal">False</span>),</span><br><span class="line"> <span class="string">'n_features_to_select'</span>: <span class="number">7</span>,</span><br><span class="line"> <span class="string">'step'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'verbose'</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">'estimator_'</span>: LinearRegression(copy_X=<span class="literal">True</span>, fit_intercept=<span class="literal">True</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">          normalize=<span class="literal">False</span>),</span><br><span class="line"> <span class="string">'n_features_'</span>: <span class="number">7</span>,</span><br><span class="line"> <span class="string">'support_'</span>: array([<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,</span><br><span class="line">        <span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>]),</span><br><span class="line"> <span class="string">'ranking_'</span>: array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">1</span>])&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Embeded"><a href="#Embeded" class="headerlink" title="Embeded"></a>Embeded</h3><blockquote>
<p>알고리즘으로 자동으로 영향력이 어느 정도인가 분류 해주는 방법.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">iris = sns.load_dataset(<span class="string">'iris'</span>)</span><br><span class="line">dt = DecisionTreeClassifier()</span><br><span class="line">dt.fit(iris.iloc[:,:<span class="number">-1</span>], iris.iloc[:,<span class="number">-1</span>]) <span class="comment"># classification에 한정해서 숫자로 바꾸지 않았을때 자동으로 바꿔줌</span></span><br><span class="line">:</span><br><span class="line">DecisionTreeClassifier(class_weight=<span class="literal">None</span>, criterion=<span class="string">'gini'</span>, max_depth=<span class="literal">None</span>,</span><br><span class="line">            max_features=<span class="literal">None</span>, max_leaf_nodes=<span class="literal">None</span>,</span><br><span class="line">            min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>,</span><br><span class="line">            min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">2</span>,</span><br><span class="line">            min_weight_fraction_leaf=<span class="number">0.0</span>, presort=<span class="literal">False</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">            splitter=<span class="string">'best'</span>)</span><br><span class="line"></span><br><span class="line">dt.predict([[<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]])</span><br><span class="line">: array([<span class="string">'virginica'</span>], dtype=object)</span><br><span class="line"></span><br><span class="line">dt.feature_importances_</span><br><span class="line">: array([<span class="number">0.</span>        , <span class="number">0.01333333</span>, <span class="number">0.06405596</span>, <span class="number">0.92261071</span>])  <span class="comment"># 각각의 숫자는 영향력의 크기를 나타낸다</span></span><br></pre></td></tr></table></figure>

<h2 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h2><blockquote>
<p>여러가지 알고리즘을 동시에 사용하여 최적의 성능을 낼수 있는 알고리즘을 생성한다</p>
</blockquote>
<h3 id="RandomForest"><a href="#RandomForest" class="headerlink" title="RandomForest"></a>RandomForest</h3><blockquote>
<p>랜덤포레스트는 분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종으로, <br><br>훈련 과정에서 구성한 다수의 결정 트리로부터 분류 또는 평균 예측치를 출력함으로써 동작한다.<br><br>성능이 좋고 overfitting이 잘 안일어난다. <br></p>
</blockquote>
<br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf=RandomForestClassifier()</span><br><span class="line">rf.fit(iris.iloc[:,:<span class="number">-1</span>], iris.iloc[:,<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">: RandomForestClassifier(bootstrap=<span class="literal">True</span>, class_weight=<span class="literal">None</span>, criterion=<span class="string">'gini'</span>,</span><br><span class="line">            max_depth=<span class="literal">None</span>, max_features=<span class="string">'auto'</span>, max_leaf_nodes=<span class="literal">None</span>,</span><br><span class="line">            min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>,</span><br><span class="line">            min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">2</span>,</span><br><span class="line">            min_weight_fraction_leaf=<span class="number">0.0</span>, n_estimators=<span class="number">10</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">            oob_score=<span class="literal">False</span>, random_state=<span class="literal">None</span>, verbose=<span class="number">0</span>,</span><br><span class="line">            warm_start=<span class="literal">False</span>)</span><br><span class="line">rf.feature_importances_</span><br><span class="line">: array([<span class="number">0.03122967</span>, <span class="number">0.02095218</span>, <span class="number">0.57202362</span>, <span class="number">0.37579453</span>])</span><br></pre></td></tr></table></figure>

<h2 id="MLxtend"><a href="#MLxtend" class="headerlink" title="MLxtend"></a>MLxtend</h2><h3 id="설치-4"><a href="#설치-4" class="headerlink" title="설치"></a>설치</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install mlxtend</span><br></pre></td></tr></table></figure>

<h2 id="Staking"><a href="#Staking" class="headerlink" title="Staking"></a>Staking</h2><h2 id="Data부터-Model-학습까지"><a href="#Data부터-Model-학습까지" class="headerlink" title="Data부터 Model 학습까지"></a>Data부터 Model 학습까지</h2><h2 id="Cross-validate-3가지"><a href="#Cross-validate-3가지" class="headerlink" title="Cross-validate 3가지"></a>Cross-validate 3가지</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Cross_val_score</span><br><span class="line">2. Cross_validate</span><br><span class="line">3. Cross_val_predict</span><br></pre></td></tr></table></figure>

<h2 id="Fit-transform-하는-3가지"><a href="#Fit-transform-하는-3가지" class="headerlink" title="Fit_transform 하는 3가지"></a>Fit_transform 하는 3가지</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> pre-processing</span><br><span class="line"><span class="number">2.</span> feature-extraction</span><br><span class="line"><span class="number">3.</span> RFE</span><br></pre></td></tr></table></figure>

<h2 id="Column-줄이는-3가지-방법"><a href="#Column-줄이는-3가지-방법" class="headerlink" title="Column 줄이는 3가지 방법"></a>Column 줄이는 3가지 방법</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. filter</span><br><span class="line">2. PCA</span><br><span class="line">3. RFE</span><br></pre></td></tr></table></figure>

<p><strong>복습시간</strong>    18시 45분 ~  22시 20분 / 총 3시간 35분  </p>

          
        </div>
        
          <br>
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2021-12-29T12:24:01+09:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>Dec 29, 2021</p>
    <!-- __('post.updated') + ' ' +  -->
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/AI/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>AI</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/Lecture/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>Lecture</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/Machine-Learning/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>Machine Learning</p></a></div>


        
      
    </div>
  </section>


        

        
            <div class="prev-next">
                
                    <section class="prev">
                        <span class="art-item-left">
                            <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;prev</h6>
                            <h4>
                                <a href="/2019/04/29/AILecture_numpy/" rel="prev" title="AI 이노베이션 스퀘어 수업(기본반) - numpy">
                                  
                                      AI 이노베이션 스퀘어 수업(기본반) - numpy
                                  
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/AI/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> AI</a> <a class="tag" href="/tags/Lecture/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> Lecture</a> <a class="tag" href="/tags/Numpy/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> Numpy</a>
                                </h6>
                            
                        </span>
                    </section>
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/2019/04/29/AILecture_pandas/" rel="prev" title="AI 이노베이션 스퀘어 수업(기본반) - pandas">
                                    
                                        AI 이노베이션 스퀘어 수업(기본반) - pandas
                                    
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/AI/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> AI</a> <a class="tag" href="/tags/Lecture/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> Lecture</a> <a class="tag" href="/tags/Pandas/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> Pandas</a> <a class="tag" href="/tags/Data-Analysis/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> Data Analysis</a>
                                </h6>
                            
                        </span>
                    </section>
                
            </div>
        
      </section>
      <!-- Google AdSense -->
      <!-- In post -->
      <script data-ad-client="ca-pub-1288998211050792" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Google AdSense -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1288998211050792"
     data-ad-slot="5437821794"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  


  







  <script>
    window.subData = {
      title: 'AI 이노베이션 스퀘어 수업(기본반) - machine learning',
      tools: true
    }
  </script>


  <div id="disqus_thread"></div>
</div>
<aside class='l_side'>
  
    
    
      
        
          <section class='widget blogger'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='/jihyeok.jpg'/>
      </div>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:wlgur278@gmail.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/Jungjihyuk"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
  </div>
</section>

        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
      
        
      
        
          
  <section class='widget toc-wrapper'>
    <header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Shortcuts</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#기계학습-분류"><span class="toc-text">기계학습 분류</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#기계학습-목적"><span class="toc-text">기계학습 목적</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data수집부터-예측까지-과정"><span class="toc-text">Data수집부터 예측까지 과정</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#label이-유한일때-무한일때"><span class="toc-text">label이 유한일때, 무한일때</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#유한일때"><span class="toc-text">유한일때</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#무한일때"><span class="toc-text">무한일때</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#masking-기법으로-missing-data-보기"><span class="toc-text">masking 기법으로 missing data 보기</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#missing-data-그래프로-확인하기"><span class="toc-text">missing data 그래프로 확인하기</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#데이터를-쪼개-성능-비교하기"><span class="toc-text">데이터를 쪼개 성능 비교하기</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#One-hot-encoding-amp-Label-encoding"><span class="toc-text">One hot encoding &amp; Label encoding</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#One-hot-encoding"><span class="toc-text">One hot encoding</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Scikit"><span class="toc-text">Scikit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Pandas"><span class="toc-text">Pandas</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LabelEncoder"><span class="toc-text">LabelEncoder</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Scikit-1"><span class="toc-text">Scikit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pandas-map"><span class="toc-text">pandas map</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bias-Variance"><span class="toc-text">Bias , Variance</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Trade-off"><span class="toc-text">Trade off</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-성능-평가하는-2가지-방법"><span class="toc-text">Model 성능 평가하는 2가지 방법</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hold-out"><span class="toc-text">Hold out</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cross-Validation-교차-검증"><span class="toc-text">Cross Validation (교차 검증)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model의-성능이-좌우되는-요소-2가지"><span class="toc-text">Model의 성능이 좌우되는 요소 2가지</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#map-vs-apply"><span class="toc-text">map vs apply</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#count-vs-size"><span class="toc-text">count vs size</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#count"><span class="toc-text">count</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#size"><span class="toc-text">size</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cut-amp-qcut"><span class="toc-text">cut &amp; qcut</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cut"><span class="toc-text">cut</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#qcut"><span class="toc-text">qcut</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discriminative-vs-Generative"><span class="toc-text">Discriminative  vs Generative</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Discriminative"><span class="toc-text">Discriminative</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Generative"><span class="toc-text">Generative</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LogisticRegression을-제일처음에-하는-이유"><span class="toc-text">LogisticRegression을 제일처음에 하는 이유</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#import를-하지-않고-외부-객체의-메소드를-사용-하는-방법"><span class="toc-text">import를 하지 않고 외부 객체의 메소드를 사용 하는 방법</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#상황에-따른-알고리즘-사용법"><span class="toc-text">상황에 따른 알고리즘 사용법</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#데이터의-양이-충분한지-판단하는-방법"><span class="toc-text">데이터의 양이 충분한지 판단하는 방법</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-curve-amp-LogisticRegression"><span class="toc-text">Learning curve &amp; LogisticRegression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#하이퍼-파라미터-찾기-GridSearchCV"><span class="toc-text">하이퍼 파라미터 찾기 (GridSearchCV)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Supervised-Learning-Process"><span class="toc-text">Supervised Learning Process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pandas-Profiling"><span class="toc-text">Pandas-Profiling</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#설치"><span class="toc-text">설치</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#예제"><span class="toc-text">예제</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#차원-축소-3가지-방법"><span class="toc-text">차원 축소 3가지 방법</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-Scaling"><span class="toc-text">Feature Scaling</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#13개-차원에서-5개-차원으로-축소"><span class="toc-text">13개 차원에서 5개 차원으로 축소</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pipeline"><span class="toc-text">Pipeline</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Pipeline만드는-두가지-방법"><span class="toc-text">Pipeline만드는 두가지 방법</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pipeline-1"><span class="toc-text">Pipeline</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#표준화"><span class="toc-text">표준화</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GridSearchCV-Pipeline-하는-방법"><span class="toc-text">GridSearchCV + Pipeline 하는 방법</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Unsupervised-Learnling"><span class="toc-text">Unsupervised Learnling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#k-means"><span class="toc-text">k-means</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means로-cluster-성능-파악하기"><span class="toc-text">k-means로 cluster 성능 파악하기</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dbscan"><span class="toc-text">dbscan</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Agglomerative-Clustering"><span class="toc-text">Agglomerative Clustering</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Dendrograms"><span class="toc-text">Dendrograms</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mglearn으로-clustering-시각화-해서-보기"><span class="toc-text">mglearn으로 clustering 시각화 해서 보기</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#설치-1"><span class="toc-text">설치</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means방식으로-clustering-하는-과정"><span class="toc-text">k-means방식으로 clustering 하는 과정</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means-boundaries"><span class="toc-text">k-means boundaries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#agglomerative"><span class="toc-text">agglomerative</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dbscan-1"><span class="toc-text">dbscan</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dbscan-k-means"><span class="toc-text">dbscan + k-means</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#알고리즘-만들기"><span class="toc-text">알고리즘 만들기</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Duck-typing-방식"><span class="toc-text">Duck typing 방식</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BaseEstimator-상속-방식"><span class="toc-text">BaseEstimator 상속 방식</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#영화-추천-모델-만들기"><span class="toc-text">영화 추천 모델 만들기</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Collaborative-filtering"><span class="toc-text">Collaborative filtering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#필요한-데이터-불러오기"><span class="toc-text">필요한 데이터 불러오기</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DESCR-README-등-도메인-정보-확인하기"><span class="toc-text">DESCR, README 등 도메인 정보 확인하기</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#불러온-정보-필요한-형태로-변형하기"><span class="toc-text">불러온 정보 필요한 형태로 변형하기</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#회원간의-상관성-보기-어떤-연관성-전략을-세울지-고민"><span class="toc-text">회원간의 상관성 보기 (어떤 연관성 전략을 세울지 고민)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#연관성이-높은-3명-뽑기-세부-전략-세우기"><span class="toc-text">연관성이 높은 3명 뽑기 (세부 전략 세우기)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#나와-비슷한-사람-영화-목록-나의-영화-목록"><span class="toc-text">나와 비슷한 사람 영화 목록 - 나의 영화 목록</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#최종-추천-영화-목록-출력하기"><span class="toc-text">최종 추천 영화 목록 출력하기</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pandas-format-대표값-설정-없이-그대로-변형하는-4가지-방법"><span class="toc-text">Pandas format 대표값 설정 없이 그대로 변형하는 4가지 방법</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pivot"><span class="toc-text">pivot</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Surprise"><span class="toc-text">Surprise</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#설치-2"><span class="toc-text">설치</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Surprise를-활용하여-예상-별점-예측하기"><span class="toc-text">Surprise를 활용하여 예상 별점 예측하기</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scikit으로-예상-별점-예측하기"><span class="toc-text">Scikit으로 예상 별점 예측하기</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#plot-knn-regression-mglearn"><span class="toc-text">plot_knn_regression (mglearn)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#recommendation-pdf-내용-추가"><span class="toc-text">recommendation.pdf 내용 추가</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Surprise-vs-Scikit"><span class="toc-text">Surprise vs Scikit</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#차이점-2가지"><span class="toc-text">차이점 2가지</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Surprise-예제"><span class="toc-text">Surprise 예제</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#os-vs-sys"><span class="toc-text">os vs sys</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Validation-curve"><span class="toc-text">Validation_curve</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Statsmodel로-regression분석하기"><span class="toc-text">Statsmodel로 regression분석하기</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#R방식"><span class="toc-text">R방식</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#설치-3"><span class="toc-text">설치</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#예제-1"><span class="toc-text">예제</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#results-summary"><span class="toc-text">results summary</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#results2-summary"><span class="toc-text">results2 summary</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Python-방식"><span class="toc-text">Python 방식</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#버전관리-2가지-방법"><span class="toc-text">버전관리 2가지 방법</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#version-information"><span class="toc-text">version-information</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#watermark"><span class="toc-text">watermark</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature-selection"><span class="toc-text">Feature-selection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3가지-방식"><span class="toc-text">3가지 방식</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Filter"><span class="toc-text">Filter</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#예시"><span class="toc-text">예시</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#wrapper"><span class="toc-text">wrapper</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Embeded"><span class="toc-text">Embeded</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ensemble"><span class="toc-text">Ensemble</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RandomForest"><span class="toc-text">RandomForest</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MLxtend"><span class="toc-text">MLxtend</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#설치-4"><span class="toc-text">설치</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Staking"><span class="toc-text">Staking</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data부터-Model-학습까지"><span class="toc-text">Data부터 Model 학습까지</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cross-validate-3가지"><span class="toc-text">Cross-validate 3가지</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fit-transform-하는-3가지"><span class="toc-text">Fit_transform 하는 3가지</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Column-줄이는-3가지-방법"><span class="toc-text">Column 줄이는 3가지 방법</span></a></li></ol>
    </div>
  </section>


        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
      
        
      
        
      
        
          
  <section class='widget category'>
    <header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;category</div>
  
    <a class="rightBtn"
    
      rel="external nofollow noopener noreferrer"
    
    
      target="_self"
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/AI/" href="/categories/AI/"><div class='name'>AI</div><div class='badge'>(10)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Data-Analysis/" href="/categories/AI/Data-Analysis/"><div class='name'>Data Analysis</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Deep-Learning/" href="/categories/AI/Deep-Learning/"><div class='name'>Deep Learning</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Machine-Learning/" href="/categories/AI/Machine-Learning/"><div class='name'>Machine Learning</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Natural-Language-Processing/" href="/categories/AI/Natural-Language-Processing/"><div class='name'>Natural Language Processing</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Numpy/" href="/categories/AI/Numpy/"><div class='name'>Numpy</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Pandas/" href="/categories/AI/Pandas/"><div class='name'>Pandas</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/AI/Python/" href="/categories/AI/Python/"><div class='name'>Python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Algorithm/" href="/categories/Algorithm/"><div class='name'>Algorithm</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Data-Structure/" href="/categories/Data-Structure/"><div class='name'>Data Structure</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/English/" href="/categories/English/"><div class='name'>English</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Git/" href="/categories/Git/"><div class='name'>Git</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/IT-Terms/" href="/categories/IT-Terms/"><div class='name'>IT Terms</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/JSP-Servlet/" href="/categories/JSP-Servlet/"><div class='name'>JSP & Servlet</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Language/" href="/categories/Language/"><div class='name'>Language</div><div class='badge'>(9)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Language/Java/" href="/categories/Language/Java/"><div class='name'>Java</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Language/Markup-Language/" href="/categories/Language/Markup-Language/"><div class='name'>Markup Language</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Language/Python/" href="/categories/Language/Python/"><div class='name'>Python</div><div class='badge'>(7)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Web/" href="/categories/Web/"><div class='name'>Web</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Bootstrap4/" href="/categories/Web/Bootstrap4/"><div class='name'>Bootstrap4</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Django/" href="/categories/Web/Django/"><div class='name'>Django</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Flask/" href="/categories/Web/Flask/"><div class='name'>Flask</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Object-Model/" href="/categories/Web/Object-Model/"><div class='name'>Object Model</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Web/Objectoriented/" href="/categories/Web/Objectoriented/"><div class='name'>Objectoriented</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
      
        
      
        
      
        
      
        
          
  <section class='widget tagcloud'>
    <header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Keywords</div>
  
    <a class="rightBtn"
    
      rel="external nofollow noopener noreferrer"
    
    
      target="_self"
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/AI/" style="font-size: 22px; color: #636363">AI</a> <a href="/tags/CodeSignal/" style="font-size: 18px; color: #7e7e7e">CodeSignal</a> <a href="/tags/CodeSignal2/" style="font-size: 14px; color: #999">CodeSignal2</a> <a href="/tags/Data-Analysis/" style="font-size: 14px; color: #999">Data Analysis</a> <a href="/tags/Deep-Learning/" style="font-size: 16px; color: #8b8b8b">Deep Learning</a> <a href="/tags/Django/" style="font-size: 14px; color: #999">Django</a> <a href="/tags/EDA/" style="font-size: 14px; color: #999">EDA</a> <a href="/tags/Flask/" style="font-size: 14px; color: #999">Flask</a> <a href="/tags/FrontEnd/" style="font-size: 14px; color: #999">FrontEnd</a> <a href="/tags/Git/" style="font-size: 14px; color: #999">Git</a> <a href="/tags/Git-Flow/" style="font-size: 14px; color: #999">Git-Flow</a> <a href="/tags/Github/" style="font-size: 14px; color: #999">Github</a> <a href="/tags/Gitlab/" style="font-size: 14px; color: #999">Gitlab</a> <a href="/tags/IT/" style="font-size: 14px; color: #999">IT</a> <a href="/tags/Java/" style="font-size: 14px; color: #999">Java</a> <a href="/tags/Jsp/" style="font-size: 14px; color: #999">Jsp</a> <a href="/tags/Lecture/" style="font-size: 22px; color: #636363">Lecture</a> <a href="/tags/Machine-Learning/" style="font-size: 16px; color: #8b8b8b">Machine Learning</a> <a href="/tags/NLP/" style="font-size: 14px; color: #999">NLP</a> <a href="/tags/Numpy/" style="font-size: 14px; color: #999">Numpy</a> <a href="/tags/Pandas/" style="font-size: 14px; color: #999">Pandas</a> <a href="/tags/Programming/" style="font-size: 14px; color: #999">Programming</a> <a href="/tags/Python/" style="font-size: 16px; color: #8b8b8b">Python</a> <a href="/tags/Servlet/" style="font-size: 14px; color: #999">Servlet</a> <a href="/tags/Web/" style="font-size: 14px; color: #999">Web</a> <a href="/tags/algorithm/" style="font-size: 22px; color: #636363">algorithm</a> <a href="/tags/api/" style="font-size: 14px; color: #999">api</a> <a href="/tags/bom/" style="font-size: 14px; color: #999">bom</a> <a href="/tags/bootstrap/" style="font-size: 14px; color: #999">bootstrap</a> <a href="/tags/class/" style="font-size: 14px; color: #999">class</a> <a href="/tags/clean-code/" style="font-size: 14px; color: #999">clean code</a> <a href="/tags/crawling/" style="font-size: 14px; color: #999">crawling</a> <a href="/tags/css/" style="font-size: 14px; color: #999">css</a> <a href="/tags/data-mining/" style="font-size: 14px; color: #999">data mining</a> <a href="/tags/database/" style="font-size: 16px; color: #8b8b8b">database</a> <a href="/tags/deep-learning/" style="font-size: 16px; color: #8b8b8b">deep learning</a> <a href="/tags/deque/" style="font-size: 14px; color: #999">deque</a> <a href="/tags/dom/" style="font-size: 14px; color: #999">dom</a> <a href="/tags/generator/" style="font-size: 14px; color: #999">generator</a> <a href="/tags/git/" style="font-size: 14px; color: #999">git</a> <a href="/tags/helper-function/" style="font-size: 14px; color: #999">helper function</a> <a href="/tags/iris/" style="font-size: 14px; color: #999">iris</a> <a href="/tags/javascript/" style="font-size: 14px; color: #999">javascript</a> <a href="/tags/js/" style="font-size: 14px; color: #999">js</a> <a href="/tags/json/" style="font-size: 14px; color: #999">json</a> <a href="/tags/neural-network/" style="font-size: 14px; color: #999">neural network</a> <a href="/tags/object/" style="font-size: 14px; color: #999">object</a> <a href="/tags/object-model/" style="font-size: 14px; color: #999">object model</a> <a href="/tags/page-rank/" style="font-size: 14px; color: #999">page rank</a> <a href="/tags/python/" style="font-size: 24px; color: #555">python</a> <a href="/tags/queue/" style="font-size: 14px; color: #999">queue</a> <a href="/tags/scraping/" style="font-size: 14px; color: #999">scraping</a> <a href="/tags/send/" style="font-size: 14px; color: #999">send</a> <a href="/tags/stack/" style="font-size: 14px; color: #999">stack</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #999">tensorflow</a> <a href="/tags/xml/" style="font-size: 14px; color: #999">xml</a> <a href="/tags/yield/" style="font-size: 14px; color: #999">yield</a> <a href="/tags/%EB%AA%85%EB%A0%B9%EC%96%B4/" style="font-size: 14px; color: #999">명령어</a> <a href="/tags/%EB%AC%B8%EB%B2%95/" style="font-size: 14px; color: #999">문법</a> <a href="/tags/%EB%B0%B1%EC%A4%80/" style="font-size: 14px; color: #999">백준</a> <a href="/tags/%EC%82%B0%ED%83%80-%ED%86%A0%EC%9D%B5/" style="font-size: 14px; color: #999">산타 토익</a> <a href="/tags/%EC%84%A4%EA%B3%84/" style="font-size: 14px; color: #999">설계</a> <a href="/tags/%EC%8B%9C%EC%9B%90%EC%8A%A4%EC%BF%A8/" style="font-size: 14px; color: #999">시원스쿨</a> <a href="/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/" style="font-size: 14px; color: #999">알고리즘</a> <a href="/tags/%EC%98%81%EC%96%B4/" style="font-size: 16px; color: #8b8b8b">영어</a> <a href="/tags/%EC%9A%A9%EC%96%B4/" style="font-size: 14px; color: #999">용어</a> <a href="/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/" style="font-size: 14px; color: #999">자료구조</a> <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/" style="font-size: 14px; color: #999">자연어 처리</a> <a href="/tags/%EC%A0%95%EB%A6%AC/" style="font-size: 18px; color: #7e7e7e">정리</a> <a href="/tags/%EC%BD%94%EB%94%A9%EC%97%B0%EC%8A%B5/" style="font-size: 20px; color: #707070">코딩연습</a> <a href="/tags/%ED%86%A0%EC%9D%B5/" style="font-size: 14px; color: #999">토익</a> <a href="/tags/%ED%95%9C%EB%88%88%EC%97%90-%EB%B3%B4%EA%B8%B0/" style="font-size: 16px; color: #8b8b8b">한눈에 보기</a> <a href="/tags/%ED%95%9C%EB%88%88%EC%97%90-%EC%A0%95%EB%A6%AC/" style="font-size: 14px; color: #999">한눈에 정리</a> <a href="/tags/%ED%98%91%EC%97%85/" style="font-size: 14px; color: #999">협업</a> <a href="/tags/%ED%9A%8C%ED%99%94/" style="font-size: 14px; color: #999">회화</a>
    </div>
  </section>


        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
  
  <!-- Google AdSense -->
  <div style="margin-top: 16px;">

  </div>
  <script data-ad-client="ca-pub-1288998211050792" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Google AdSense -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1288998211050792"
     data-ad-slot="7750297977"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

<footer class="clearfix">
  
    <div class="social-wrapper">
      
        
          <a href="mailto:wlgur278@gmail.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/Jungjihyuk"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <!-- <div><- markdown(__('footer.license')) </div> -->
  <div>
    <!-- <- __('footer.use')  -->
    <!-- a href = "<- theme.info.docs " -->
    <span>Copyright. </span>
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material-X</a>
    <!-- <- theme.info.name    -->
    <!-- <- __('footer.theme')  -->
    <br>
    
    . 
  </div>
  
</footer>
<script>setLoadingBarProgress(80);</script>

<script>

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-jungjihyuk-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>

      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>

<script async src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>

  <script async src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>
  <script async src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>





  
  
  
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["unsplash.jpg", "jonathan.jpg", "flower.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["unsplash.jpg", "jonathan.jpg", "flower.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  











  
<script src="/js/app.js"></script>



  
<script src="/js/search.js"></script>



  
    
<script src="/js/commentTyping.js"></script>

  





<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
